<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[操作系统知识总结3]]></title>
    <url>%2F2018%2F07%2F04%2Fall-os3%2F</url>
    <content type="text"><![CDATA[存储器管理存储器的层次结构 CPU 寄存器 Cache 高速缓存 主存储器（内存/主存） 磁盘缓存 固定磁盘 可移动存储介质 在存储层次中，层次越高（越靠近 CPU），存储介质的访问速度越快，价格也就越高，相应所配置的存储容量也越小。高速缓存、主存储器和磁盘缓存均属于操作系统存储管理的管辖范畴，掉电后存储的信息就不存在了。而低层的固定磁盘和可移动存储介质则属于设备管理的管辖范畴，它们存储的信息将被长期保存。 存储器的管理目标 为用户使用存储器提供方便，用户只需要在自己的逻辑内存空间编程，不需要考虑真实内存的物理位置。 为用户提供充分大的存储空间。 提高内存的利用率，将尽量多的用户调入内存运行。 程序的装入和链接程序进入内存的流程步骤： 编译：源代码 -&gt; 目标模块 链接：目标模块 + 库函数 -&gt; 装入模块 装入：装入内存 连续分配方式为了能将用户程序装入内存，必须为它分配一定大小的内存空间。连续分配方式是最早出现的一种存储器分配方式，该方式是为一个用户程序分配一个连续的内存空间。有以下几种分配方式： 单一连续分配在单道程序环境下，内存分为系统区和用户区两部分。整个内存的用户空间由该程序独占。 固定分区连续分配（容易造成浪费）将内存划分为多个区域，每个区域大小固定且只能装入一个程序。分区大小相等的划分一般用于多个相同任务；分区大小不等的划分一般根据实际任务大小分配。 动态分区分配无固定分区，在整块内存空间中动态分割；根据程序大小，动态分配连续的内存空间，分配的内存大小等于程序大小。 基于顺序搜索的动态分区分配算法为了实现动态分区分配，通常是将系统中的空闲分区链接成一个链。顺序搜索，是指依次搜索空闲分区链上的空闲分区，去寻找一个其大小能满足要求的分区。有以下几种算法： 首次适应算法首次适应（First Fit, FF）算法是按顺序选择第一个满足要求的内存区域。优点：保留了高地址的大部分空间，为以后到达的大作业分配大的内存空间创造了条件。缺点：低址部分不断被划分，会留下许多难以利用的、很小的空间（碎片）。 循环首次适应算法循环首次适应（Next Fit, NF）算法是在上一次找到空闲分区的下一个分区开始寻找，找到第一个满足要求的内存区。优点：空闲分区在内存中分配均匀，查找时间短。缺点：缺乏大的内存空间。 最佳适应算法最佳适应（Best Fit, BF）算法是指每次为作业分配内存时，总是把能满足要求、又是最小的空闲分区分配给作业，避免“大材小用”。优点：提高内存利用率，保留大空闲区。缺点：仍然存在小片无法利用的空闲分区（碎片）。 动态可重定位分区分配对内存中正在使用的分区进行搬迁，使多个小的空闲分区（碎片）合并为一个大的空闲分区。]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统知识总结2]]></title>
    <url>%2F2018%2F07%2F04%2Fall-os2%2F</url>
    <content type="text"><![CDATA[处理机调度处理机调度的层次 高级调度（作业调度）根据调度算法和计算机状态，从外存选择一个或多个作业调入内存。 创建进程 分配内存等资源 将进程放入就绪队列等待 CPU 调度。 低级调度（进程调度）它决定哪个进程获得 CPU。 保存现场 调度新进程 新进程获得 CPU 控制权 中级调度（内存调度）中级调度是为了提高内存利用率和系统吞吐量。为此，把那些暂时不能运行的进程调至外存等待，此时进程的状态为挂起状态。当它们具备运行条件且内存又稍有空闲时，再重新调入内存，并修改器状态为就绪状态。 三级调度队列模型 处理机调度常见名词 到达时间：进入系统的时间 开始时间：首次使用 CPU 的时间 服务时间：需要使用 CPU 的时间，也叫“运行时间” 完成时间：退出系统的时间 周转时间：完成时间 - 到达时间 带权周转时间：周转时间 / 服务时间 平均周转时间：周转时间的平均值 平均带权周转时间：带权周转时间的平均值 调度算法 先来先服务调度算法先来先服务（First-Come First-Served, FCFS）调度算法按照作业到达的先后次序进行调度，它优先考虑在系统中等待时间最长的作业。（不利于短作业）FCFS 算法在单处理机系统中已很少作为主调度算法，但经常把它与其它调度算法相结合使用，形成更有效的调度算法。例如可以在系统中按进程的优先级设置多个队列，每个优先级一个队列，其中每一个队列的调度算法都基于 FCFS 算法。 短作业优先调度算法短作业优先（Short Job First, SJF）调度算法以作业的长短来计算优先级，它从外存的后备队列中选择若干个估计运行时间最短的作业，优先将它们调入内存运行。（不利于长作业，未考虑作业的紧迫程度） 优先级调度算法前面两种算法不能反映作业的紧迫程度，在优先级调度算法（Priority-Scheduling Algorithm, PSA）中，则是基于作业的紧迫程度，由外部赋予作业相应的优先级，调度算法是根据该作业的优先级进行调度的。 高响应比优先调度算法高响应比优先调度算法（Highest Response Ratio Next, HRRN）既考虑了作业的等待时间，又考虑了额作业的运行时间。优先权 = (等待时间 + 服务时间) / 服务时间等待时间相同，服务时间越短优先权越高；服务时间相同，等待时间越长优先权越高。（每次调度前都要计算优先权，增加系统开销） 基于时间片的轮转调度算法 将所有就绪进程按先来先服务排成队列 把 CPU 分配给队首进程，进程只执行一个时间片 时间片用完，OS 通过计时器发出时钟中断，停止进程 将已使用时间片的进程送至就绪队列末尾 分配 CPU 给就绪队列的下一个进程 多级反馈队列调度算法设置多个就绪队列，各个队列优先级逐个降低，时间片长度成倍增加。即，优先级越高的队列执行时间片就越短。多级反馈队列调度算法的调度规则： 每个新进程首先进入第一个队列，遵循 FCFS。 在当前队列的时间片内，进程若能完成，退出。 进程若未完成，降到第二个队列，同样遵循 FCFS。 依此类推…… 低级队列只有等高级队列变空才能执行。 当高级队列有新进程进入，而当前正在运行低级队列的进程，将立即发生抢占，被抢占进程放回低级队列的末尾，记录进程剩余运行时间和在当前队列的剩余使用时间。 实时调度在实时系统中，可能存在着一些实时任务，它们都联系着一个截止时间。为保证系统能正常工作，实时调度必须能满足实时任务对截止时间的要求。 最早截止时间优先算法最早截止时间优先（Earliest Deadline First, EDF）算法是根据任务的截止时间确定任务的优先级，任务的截止时间越早，其优先级越高，具有最早截止时间的任务排在队列的队首。 最低松弛度优先算法最低松弛度优先（Least Laxity First, LLF）算法是根据任务紧急程度确定任务的优先级，任务的紧急程度越高，优先级就越高。松弛度 = 完成截止时间- 运行时间(服务时间) - 当前时间例如，任务 A 的完成截止时间是第 400s，运行时间为 100s，当前时间是第 150s，则 A 的松弛度 = 400-100-150 = 150s 在松弛度为 0 的时刻设置“地雷”，松弛度为 0 发生抢占。 死锁产生死锁的必要条件 互斥进程对所分配的资源进行排它性使用，即在一段时间内，某资源只能被一个进程占用。如果此时还有其它进程请求该资源，则请求进程只能等待，直到占有该资源的进程释放。 请求与保持进程已经持有了至少一个资源，但又提出新的资源请求。 不可剥夺已获得的资源在使用完之前，不能被抢占，只能在进程使用完自己释放。 环路等待存在一个“进程——资源”循环链，进程间互相等待资源。 处理死锁的方法 预防死锁设置限制条件，破坏产生死锁的一个或多个必要条件。比如，强制回收资源、资源一次性分配…… 避免死锁在资源动态分配过程中，加入检查，防止系统进入不安全状态。 检测死锁建立检测机构检测死锁的发生和原因，确定相关的进程和资源。 解除死锁剥夺资源或撤销进程，从而解除死锁。 避免死锁的方法在死锁避免方法中，把系统的状态分为安全状态和不安全状态。当系统处于安全状态时，可避免发生死锁。反之，当系统处于不安全状态时，则可能进入到死锁状态。所谓安全状态，是指系统能按某种进程顺序 &lt;P1, P2, …，Pn&gt; 来为每个进程Pi分配其所需资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利地完成，称 &lt;P1, P2, …, Pn&gt; 序列为安全序列。如果系统无法找到这样一个安全序列，则称系统处于不安全状态。 数据结构的定义： 定义 描述 Max 进程对各种资源的最大需求 Allocation 进程已占用（分配）的各种资源的数量 Need 进程对各种资源的剩余需求量 Available 系统当前可用资源数量 Work 每个进程完成后系统可用资源数量（初始值为 Available） Finish 每个进程能否完成 银行家算法银行家算法原本是为银行系统设计的，以确保银行在发放现金贷款时，不会发生不能满足所有客户需要的情况。当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给该进程。若有，再进一步计算在将这些资源分配给进程后，是否会使系统处于不安全的状态。如果不会，才将资源分配给它。判断方法： 虚拟执行这个分配请求，使得当前状态进入下一个状态； 在下一个状态中寻找安全序列； 若找到，说明状态安全，可以执行分配请求；否则拒绝分配请求。 算法缺点： 很少进程能够在运行前就知道它所需资源的最大值。 系统内的进程数是不固定的，往往在不断变化，有新的进入，有完成的退出。 😄 To be continued.👉 Next.👉 Previous.]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统知识总结]]></title>
    <url>%2F2018%2F07%2F01%2Fall-os%2F</url>
    <content type="text"><![CDATA[操作系统概论操作系统的作用 作为用户与计算机硬件系统之间的接口。 作为计算机系统资源的管理者。 实现对计算机资源的抽象。 操作系统的四个基本特性 并发在一段时间内多个程序并发执行。 共享系统中的资源可以被内存中多个并发执行的进线程共同使用。 虚拟通过分时系统以及虚拟内存技术实现把一个物理实体虚拟为若干个逻辑上的对应物。 异步系统中的进程以不可预知的速度向前推进，但只要运行环境相同，多次运行都会获得完全相同的结果。 操作系统的主要功能 处理机管理：进程控制、进程同步、进程通信、CPU 调度 存储器管理：内存分配、地址映射 设备管理：缓冲管理、设备分配、设备处理、虚拟设备 文件管理：存储空间管理、目录管理 用户接口：图形接口、命令接口 进程基本概念程序顺序执行的特征 顺序性：下一操作要等待前一操作执行结束。 封闭性：执行独占资源，不受外界影响。 可再现性：重复执行得到相同结果。 程序并发执行的特征 间断性 失去封闭性 不可再现性：重复执行可引发多种结果。 程序并发的三个特征使得程序不能并发地正确执行，为了保证程序并发执行，引入进程。 进程的结构进程由程序、数据、进程控制块(PCB)三部分组成。 程序：代码段，描述进程要完成的功能。 数据：数据段，进程执行时所需要的数据区。 进程控制块：一种数据结构，用于标识进程的存在，记录进程执行过程中各个时刻的状态特征。 进程的四个特性 动态：进程具有生命周期，从创建，执行，到消亡。 并发：多个进程共存于内存中，并发执行。 独立：进程间资源独立，互不干扰。进程是系统进行资源分配和调度的一个独立单位。 异步：每个进程都以其相对独立，不可预知的速度前进。 进程与程序的区别 进程是动态的执行实体，程序是静态的数据与指令的集合。 一个程序可以包含多个进程。 进程用于并发执行与接受调度，程序用于存储数据和接受系统启动。 进程执行需要 CPU，程序存储需要存储器。 进程具有生命周期，程序是永存的。 进程的三种基本状态 就绪状态：已获得除 CPU 以外的其他所有资源，处于就绪队列，等待 CPU 调度。 执行状态：获得 CPU，处于执行过程。 阻塞状态：某个事件暂时无法进行，主动放弃 CPU。 PCB 的作用PCB 中包含进程标识符、处理机状态、进程调度信息、进程控制信息。所以 PCB 具有以下作用： 进程存在的唯一标识 记录进程的外部特征 描述进程变化的过程 记录进程和其他进程的联系 PCB 的组织方式 链接方式：把具有相同状态的进程的 PCB 分别通过 PCB 中的链接字段链接成一个队列。优先级高的进程 PCB 排在队列前面。 索引方式：根据进程状态的不同建立索引。 原语操作原语由若干指令组成，是用于完成一定功能的一个过程。原语操作是一种原子操作；原语中的操作要么全做，要么全不做。 进程控制进程创建 申请空白 PCB； 为新进程分配资源； 初始化 PCB； 如果进程就绪队列能够接纳新进程，就将新进程插入就绪队列。 进程终止 根据标识符从 PCB 集合中检索出 PCB，读取进程状态； 若正处于执行状态，立即终止该进程的执行，并置调度标志位真，在进程被终止后重新调度； 终止该进程的子孙进程，以防止成为不可控的进程； 回收资源，归还给父进程/系统； PCB 移出所在队列或链表。 进程阻塞（对应唤醒）执行过程中，当发现引发阻塞的事件而无法继续执行时，进程调用阻塞原语block把自己阻塞。 停止当前执行； 修改状态，由执行改为阻塞； 将 PCB 插入阻塞队列，若有因不同事件而划分的多个阻塞队列，阻塞进程插入相应队列； 重新调度，将处理机分配给另一就绪进程； CPU 环境切换，保存被阻塞进程的 CPU 状态到 PCB 中，按新进程 PCB 的 CPU 状态设置 CPU 新环境。 进程唤醒被阻塞的事件已满足，如 I/O 完成或所需数据已到达，则由有关进程调用唤醒原语wakeup，将阻塞的进程唤醒： 先把被阻塞的进程从等待该事件的阻塞队列中移出； 将其 PCB 状态由阻塞改为就绪； 再将该 PCB 插入到就绪队列中。 进程挂起（对应激活）挂起是将活动状态改为静止状态的过程。 挂起一般有以下几个原因： 终端用户的请求：当终端用户发现自己程序运行期间有可疑进程时，需要挂起检查。 父进程的请求：有时父进程希望挂起自己的某个子进程，以便考察和修改子进程，或者协调各子进程间的活动。 负载调节的需要：保证系统正常运行。 操作系统的需要：操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况。 挂起原语的执行过程如下： 检查被挂起进程的状态，活动就绪改为静止就绪；活动阻塞改为静止阻塞； 将 PCB 复制到指定的内存区域； 数据复制到外存，释放内存； 若被挂起的进程正在执行，则重新调度。 进程激活当发生激活进程的事件，如父进程或用户进程请求激活，或当前内存有足够的空间，系统利用激活原语active将进程激活。 激活原语的执行过程如下： 先将进程从外存调入内存； 检查该进程的现行状态，静止就绪改为活动就绪；静止阻塞改为活动阻塞； 若是进入就绪队列，则重新调度，抢占式和非抢占式调度。 进程同步进程同步的任务是使并发执行的诸进程之间能有效地共享资源和相互合作，从而使进程的执行具有可再见性。同步机制应遵循的规则： 空闲让进 忙则等待 有限等待 让权等待 信号量机制 整型信号量使用一个代表资源数目的整型变量。未遵循“让权等待”规则。 记录型信号量增加一个进程链表 L，用于链接所有等待进程。初始值为 1，表示只允许一个进程访问临界资源，此时的信号量转换为互斥信号量。 AND 型信号量将进程在整个运行过程中需要的所有资源，一次分配给进程，待进程使用完后再一起释放。即：要么全部分配到进程，要么一个也不分配。 管程管程是一种共享数据结构，对该共享数据结构实施的特定操作定义为一组过程。进程对共享资源的申请、释放和其他操作必须通过这组过程。 局部数据变量只能被管程的过程访问，任何外部过程都不能访问。 一个进程通过调用管程的一个过程进入管程。 在任何时候，只能有一个进程在管程中执行，调用管程的任何其它进程都被阻塞。 生产者——消费者问题可以利用“记录型信号量、AND 型信号量、管程”来解决生产者——消费者问题，这里演记录型信号量的使用。假设有n个缓冲区。 变量 功能/描述 mutex 实现诸进程对缓冲区的互斥访问（公有） empty 缓冲池中空缓冲区的数量（私有） full 缓冲池中满缓冲区的数量（私有） 1234567891011// 生产者producer:begin repeat produce an item nextp; wait(empty); // 先私 wait(mutex); // 后公 buffer(in) ∶= nextp; in ∶= (in + 1) mod n; signal(mutex); signal(full); until false; 12345678910// 消费者consumer:begin repeat wait(full); // 先私 wait(mutex); // 后公 nextc ∶= buffer(out); out ∶= (out + 1) mod n; signal(mutex); signal(empty); consume the item in nextc; 哲学家进餐问题五个哲学家进餐，如何避免死锁？ 至多只允许有四位哲学家同时去拿左边的筷子 当哲学家的左、右两只筷子均可用时，才允许他拿起筷子进餐。 规定奇数号哲学家先拿他左边的筷子，然后再去拿右边的筷子；而偶数号哲学家则相反。 读者——写者问题 一个数据文件可被多个进程共享 允许多个进程同时读，禁止多个进程同时写 当一个进程写的时候，其他所有读进程都要停止 当进程读的时候，不允许写进程的发生。 读写是互斥的。 12345678910111213141516171819202122232425var rmutex, wmutex:semaphore = 1, 1; readcount:integer = 0; begin parbegin reader:begin repeat wait(rmutex); if readcount = 0 then wait(wmutex); readcount ∶= readcount + 1; signal(rmutex); perform read operation; wait(rmutex); readcount = readcount - 1; if readcount = 0 then signal(wmutex); signal(rmutex); until false; end writer:begin repeat wait(wmutex); perform write operation; signal(wmutex); until false; 进程通信进程间通信（IPC, InterProcess Communication）是指在不同进程之间传播或交换信息。 进程通信方式 共享内存（最快）同一块物理内存被映射到进程 A、进程 B 各自的进程空间。进程 A 可以即时看到进程 B 对共享内存中数据的更新，反之亦然。由于多个进程共享同一块内存区域，必然需要使用同步机制，互斥锁和信号量都可以。 管道管道是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又叫pipe文件。写进程：以字符流形式将大量的数据送入共享文件，即送入管道。读进程：从管道中接收数据，即从共享文件中读数据。管道只支持半双工通信（单向传输）；只能在父子进程中使用；管道实质是采用文件的读写操作，支持大数据量的传输。 命名管道即 FIFO 文件，通过命名管道可以实现在不相关的进程之间交换数据。 消息队列消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。每个数据块都被认为含有一个类型，接收进程可以独立地接收含有不同类型的数据结构。相比于 FIFO，消息队列具有以下优点： 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 套接字与其它通信机制不同的是，它可用于不同机器间的进程通信。 进程与线程的区别 地址空间进程之间是独立的地址空间，而同一进程的线程则共享本进程的地址空间。 资源拥有进程之间的资源是独立的，而同一进程内的线程共享本进程的资源，如内存、I/O、CPU 等。一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃后整个进程都死掉。所以多进程要比多线程健壮。 执行过程每个独立的进程有一个程序运行的入口、顺序执行序列和程序入口，而线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 线程是处理机调度的基本单位，但是进程不是。 因此，对资源的管理和保护要求高、不限制开销和效率时，使用多进程。要求效率高、频繁切换、资源的保护管理要求不是很高时，使用多线程。 😄 To be continued.👉 Next.]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络——应用层]]></title>
    <url>%2F2018%2F06%2F30%2Fapplication-layer%2F</url>
    <content type="text"><![CDATA[HTTP 协议HTTP 协议（HyperText Transfer Protocal, 超文本传输协议）是用于从 WWW 服务器传输超文本到本地浏览器的传送协议。它基于 TCP 协议之上，属于应用层协议。 HTTP 请求响应模型HTTP 是一个无状态的协议。无状态是指客户端和服务器之间不需要建立持久的连接，这意味着当一个客户端向服务器发送请求，服务器返回响应之后，连接即关闭了，在服务端不保留连接的有关信息。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络——传输层]]></title>
    <url>%2F2018%2F06%2F29%2Ftransport-layer%2F</url>
    <content type="text"><![CDATA[传输层概述在 OSI（Open System Interconnection, 开发系统互联）七层模型中，传输层是面向通信的最高层，也是面向用户功能的最底层。 传输层有两大功能： 复用：在发送端，多个应用进程共有一个传输层。 分用：在接收端，传输层根据端口号将数据分派给不同的应用进程。 传输层和网络层的区别： 网络层是为不同主机提供通信服务，而传输层是为不同主机的不同应用程序提供通信服务。 网络层只对报文头部进行差错检测，而传输层对整个报文进行差错检测。 UDP 协议UDP 的特点UDP（User Datagram Protocol, 用户数据报协议）有以下特点： 无连接通信前不需要建立连接，通信结束也无须释放连接。 不可靠UDP 是尽力而为交付，不能确保每个数据报都送达。 面向报文UDP 数据传输的基本单位是报文，它不会对数据做任何拆分或拼接操作。在发送端，应用程序给传输层的 UDP 什么数据，UDP 不会对数据进行拆分，只增加一个 UDP 头后就交给网络层；在接收端，UDP 收到网络层的数据报后，不会作任何拼接操作，去掉数据报头后便交给应用层。 没有拥塞控制UDP 始终以恒定的速率发送数据，它不会根据网络拥塞情况对发送速率作出调整。这种方式可能导致数据丢失，但可以应用在“直播、语音通话”这种允许数据丢失、但对实时性要求较高的场景。 支持一对一、一对多、多对一、多对多通信 首部开销小，只有 8 字节 UDP 头部UDP 头部只有 8 字节，包括： 16 位源端口 16 位目的端口 16 位 UDP 长度 16 位 UDP 检验和 TCP 协议TCP 的特点TCP（Transmission Control Protocol, 传输控制协议）有以下特点： 面向连接通信前需要建立连接，通信结束后需要释放连接。 可靠TCP 发送的数据无重复、无丢失、与发送端顺序一致。 面向字节流TCP 以字节位单位，传输的过程中数据被划分成一个个数据报。 全双工通信TCP 的两端既可以作为发送端，也可以作为接收端。 一条 TCP 连接的两端只能有两个端点TCP 只能提供点到点的通信，而 UDP 可以任意方式的通信。一条 TCP 连接的两端就是两个套接字，套接字 = IP: 端口号。 TCP 头部TCP 头部通常有 20 字节，有选项时更长，但总共不超过 60 字节。包括： 源端口、目的端口（共 4 字节）传输层和网络层的一大重要区别就是：传输层指定了数据报发往的应用进程，因此需要端口号标识。 序号（4 字节）当前 TCP 数据报数据部分的第一个字节的序号。TCP 是面向字节流的，它会对发送的每一个字节进行编号，而且不同数据报之间是连续编号的。 确认号（4 字节）表示当前主机作为接收端，期望接收的下一个字节的编号。 数据偏移（4 字节）数据部分距离报文段起始部分的偏移，其实就是头部的长度。 保留字段 标识符 URG：该字段被置 1 时，表示当前数据报的数据部分包含紧急信息，紧急数据一定是在数据部分的最前面，紧急指针标明了紧急数据的尾部。 ACK：该字段被置 1 时，确认号字段才有效。在连接建立后传送的所有报文短都必须把 ACK 置 1。 PSH：当接收方收到 PSH=1 的报文后，会立即将数据交给应用程序，而不是等到缓冲区满了后才提交。 RST：该值为 1 时，表示当前 TCP 连接出现严重问题，需要释放重连。 SYN：SYN 在建立连接的时候使用。（SYN=1, ACK=0）表示当前报文段是一个连接请求报文；（SYN=1, ACK=1）表示当前报文是一个同意建立连接的应答报文。 FIN：FIN=1 表示此报文段是一个释放连接的请求报文。 接收窗口大小表示当前接收窗口的剩余容量大小，用于实现 TCP 的流量控制。发送方收到该值后会将发送窗口调整为该值的大小。发送窗口的大小又影响了发送速率，所以接收方通过设置该值控制发送方的发送速率。 检验和用于接收端检验整个数据报在传输过程中是否出错。 紧急指针用于标识紧急数据的尾部。 选项字段长度可选。 TCP 三次握手假设 A 为客户端，B 为服务端。 首先 B 处于LISTEN状态，等待 A 的连接请求。 A 向 B 发送请求报文， （SYN=1, ACK=0），发送后 A 进入SYN-SENT状态。 B 收到 A 的请求报文，如果同意建立连接，则向 A 发送连接确认报文段，（SYN=1, ACK=1），发送后 B 进入SYN-RCVD状态。 A 收到 B 的连接确认报文段，还要向 B 发送一个确认报文段，发送后 A 进入ESTABLISHED状态，B 收到后也进入ESTABLISHED状态，从而连接建立。 为什么是三次握手？而不是两次？其实是防止失效的连接被服务端接收，导致服务端错误打开连接而浪费资源。如果建立连接只需要两次握手，客户端没有太大变化，它在获得服务端的应答后进入ESTABLISHED状态，而服务端会在收到连接请求后就进入ESTABLISHED状态。此时如果网络拥塞，客户端发送的请求迟迟到不了服务端，客户端会超时重发，如果服务端正确接收并确认应答，双方开始通信，通信接收后释放连接。此时如果那个失效的连接请求抵达服务端，由于只有两次握手，服务端会进入ESTABLISHED状态，而此时客户端早已进入CLOSED状态，服务端会一直等待下去，从而浪费服务端连接资源。 TCP 四次挥手TCP 连接的释放一共需要四步，称为“四次挥手”。前两次挥手用于断开一个方向的连接，后两次挥手用于断开另一个方向的连接。 A 发送连接释放报文段， FIN=1，之后进入FIN-WAIT-1状态。 B 收到后，向 A 发送连接应答，进入CLOSE-WAIT状态。 A 收到该应答，进入FIN-WAIT-2状态，等待 B 发送连接释放的请求。 当 B 不再需要连接时，向 A 发送连接释放的请求报文， FIN=1，之后 B 进入LAST-ACK状态。 A 收到释放请求后，向 B 发送应答，进入TIME-WAIT状态，等待 2MSL 后进入CLOSED状态，B 收到应答后，也进入CLOSED状态。 为什么 A 要先进入TIME-WAIT状态，等待 2MSL 时间后再进入CLOSED状态？其实是为了保证 B 能收到 A 的确认应答。若 A 发完确认应答后直接CLOSED，如果该应答丢失，B 等待超时，会重新发送释放连接的请求，此时 A 已经关闭了，不会作出任何响应，B 永远无法正常关闭。 TCP 可靠传输的表现TCP 的可靠性在于，它向应用层提供的数据是无差错、有序、无丢失的。TCP 采用流量控制、拥塞控制、连续 ARQ 等技术保证它的可靠性。 停止等待协议（ARQ 协议）TCP 保证其可靠性采用的是更为复杂的滑动窗口协议，但停止等待协议是它的简化版，因此这里先介绍停止等待协议。ARQ（Automatic Repeat reQuest, 自动重传请求），就是当请求失败时它会自动重传，直到请求被正确接收为止。 无差错的情况A 向 B 每发送一个分组，都要停止发送，收到 B 的确认应答后才发送下一个分组。 分组丢失、出现差错的情况分组丢失：分组在途中丢失，B 收不到，因此不会有响应，A 超时后会重传。出现差错：B 收到分组，但检查到分组有差错，会直接丢弃，不会有响应，A 同样超时重传。 应答丢失、应答迟到的情况应答丢失：B 收到分组，返回应答，但应答在途中丢失了，A 超时重传，紧接着 B 又收到该分组，判断该是否已接收，若已接收则直接丢弃，并补上一个应答。应答迟到：B 收到分组，返回应答，但由于网路拥塞，A 没有及时收到分组，导致超时重传，之后前面的应答抵达 A，A 判断是否已接收，若是则直接丢弃即可。 滑动窗口协议（连续 ARQ 协议）在 ARQ 协议中，发送者每次只能发送一个分组，在应答到来前必须等待，而连续 ARQ 协议的发送者拥有一个发送窗口，发送者可以在没有得到应答的情况下连续发送窗口中的分组。这样减少了等待时间，提高了传输的效率。 窗口是缓存的一部分，用来暂时存放字节流。发送者和接收者各有一个窗口，接收者通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送者根据这个值和其它信息设置自己的窗口大小。 如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 如果某些字节并未按序收到，接收者只会确认最后一个有序的字节，从而乱序的字节就会被重新发送。 TCP 协议的两端分别为发送者 A 和接收者 B，由于是全双工通信，因此 A 和 B 应该分别维护着一个独立的发送缓冲区和接收缓冲区。 TCP 流量控制流量控制是为了避免分组丢失，通过控制发送方发送速率，保证接收方来得及接收。它通过滑动窗口协议实现。 流量控制可能引发死锁。当发送者收到一个窗口为 0 的应答时，进入等待状态，等待接收者的下一个应答。如果下一个窗口不为 0 的应答在途中丢失，会导致发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待下去，从而产生死锁。为了避免死锁，TCP 使用了持续计时器，每当发送者收到一个 0 窗口的应答后就启动计数器，时间一到会询问接收者窗口的大小。若依然为 0，则重新启动计时器，如此下去…… TCP 拥塞控制如果网络出现拥塞，分组将会丢失，此时发送者会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送者的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收者能来得及接受，而拥塞控制是为了降低整个网络的拥塞程度。 TCP 主要通过四种算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。 发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 慢开始与拥塞避免发送的最初执行慢开始，令 cwnd=1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 …注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。如果出现了超时，则令 ssthresh = cwnd/2，然后重新执行慢开始。 快重传与快恢复对于接收者，要求每次接收到报文段都应该发送对已收到有序报文段的确认，例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。而对于发送方，如果收到三个重复确认，那么可以确定下一个报文段丢失，例如收到三个 M2 ，则 M3 丢失。此时执行快重传，立即重传下一个报文段。在这种情况下，只是丢失个别报文段，而不是网络拥塞，因此执行快恢复，令 ssthresh = cwnd/2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>UDP</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[免费搭建属于自己的博客]]></title>
    <url>%2F2018%2F06%2F29%2Fbuild-your-own-blog%2F</url>
    <content type="text"><![CDATA[对于一个没有一点编程基础的同学来说，搭建这样的一个博客，难吗？ 不难，说真的。但不是说很简单，它需要你去了解一些小知识点，比如 Git 命令行的使用、GitHub 仓库的创建、代码的远程部署等等……它不像我们安装某些软件一样，只要把安装包下载下来，运行安装程序，一路 next 到最后完成即可。 这篇文章里，我会大致说一下搭建的流程以及用到的每个工具的作用，但不会详细讲一步步具体该怎么操作，因为网上有太多详细的教程了，只要你会用搜索引擎。 安装 GitGit 是一个版本控制软件，或者说是一个管理代码的工具，特别适合用于团队的协作开发中。在公司，一般是团队协作完成软件/系统的开发，同事把代码提交到远程仓库，你可以在自己电脑上通过 Git 命令将代码克隆下来，创建分支，加进去你的代码，提交的时候可以 merge 合并分支，协作完成开发工作。 我们搭建自己的博客，需要将代码部署到 GitHub 上，用的就是 Git 的一些基本命令，比如 commit、push… 安装 Node.js我的这个博客用的是 Hexo 框架，它基于 Node.js 开发，因此，在安装 Hexo 之前，首先需要安装 Node.js。而 npm 是 Node.js 的一个包管理工具，安装完 Node.js 之后，就有了 npm。通过 npm 我们可以把搭建博客需要的一些代码包（如 Hexo）下载下来并完成安装。 安装 Hexo通过执行 npm 命令安装即可。 初始化博客安装完 Hexo，在自己喜欢的文件夹下初始化 Hexo 博客，并配置一些相关信息，比如博客网站的标题、语言(zh-Hans)等等。 安装主题这一步可以不做，你完全可以用 Hexo 的默认主题，只是我嫌弃它默认的主题样式不好看，因此安装了 nexT 主题样式，看起来舒服多了，这个过程可以做一些个性化配置，比如文章的展示方式……只要在主题文件夹下修改 _config.yml 文件的配置信息即可。 在 GitHub 上创建仓库以上我们是在自己电脑上操作的，外部无法访问到我们的博客，因此，可以将页面代码部署到 GitHub 仓库上，由 GitHub 帮我们解析页面供外部访问。部署的时候，需要有密钥，一般是用 SSH，保证只有自己能上传代码到自己的仓库上。部署完成之后，基本上就搞定了。 添加 GitmentGitment 是一款基于 GitHub Issues 的评论系统，可以为我们的博客添加评论功能，完全不需要后台服务器，用户的每一条评论会存储到 GitHub 的 Issues 上，你可以像我一样，将评论添加在自己的博客仓库中，也可以新创建一个仓库专门用于存储评论。 评论时需要用户登录 GitHub 账号，没有 GitHub 账号的用户是评论不了的，这与 Gitment 基于 GitHub Issues 有关。 似乎就这么多了，详细的搭建过程以及如何开始文章的创作，查看网上教程就好了，我就不把链接贴出来了~]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再见，德国]]></title>
    <url>%2F2018%2F06%2F28%2FGoodbye-Germany%2F</url>
    <content type="text"><![CDATA[生活无比残酷，幸运女神不会永远眷顾着你，还是要坚强面对生活。 再见，日耳曼战车。]]></content>
      <categories>
        <category>Life</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Just Do IT]]></title>
    <url>%2F2018%2F06%2F27%2FJust-Do-IT%2F</url>
    <content type="text"><![CDATA[复习计划 JVM Java Web Spring MyBatis 设计模式 操作系统 数据库 计算机网络 数据结构与算法 Java 基础 Java 并发 Java 容器 Java IO]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>plan</tag>
      </tags>
  </entry>
</search>
