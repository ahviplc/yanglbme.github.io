<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[设计模式系列——工厂模式]]></title>
    <url>%2F2018%2F07%2F16%2Ffactory-pattern%2F</url>
    <content type="text"><![CDATA[前言工厂模式，是根据“需求”生产“产品”，说点白就是“你要什么对象，从工厂拿就好了”。那么，我们自己在代码中创建对象不就好了吗？为什么还要去使用工厂模式？ 工厂模式的作用其实，工厂模式是为了解耦：把对象的创建和使用过程分开。这样使得系统更加符合“单一职责原则”，有利于功能的复用和对象创建过程的修改维护。还有一个好处是，防止用来实例化一个类的数据和代码在多个类中重复出现，简而言之，就是降低代码重复率。 另外，使用工厂类可以提高代码的可读性。我们知道，一个类可能有多个构造函数，用户传入不同的参数来调用相应的构造函数，从而创建对象。而我们从构造函数和参数也许看不出差异，如果将对象的创建过程封装在工厂类中，我们就可以提供一系列名字完全不同的工厂方法，每个工厂方法对应一个构造函数，这样可读性更高。 工厂模式的分类根据业务场景的不同会有不同的实现方式。一般分为以下三种： 简单工厂 工厂方法 抽象工厂 这三种方式从简单到抽象，实现方式也是越来越复杂。 简单工厂简单工厂模式功能类的编写步骤如下： 编写抽象产品接口 编写接口实现类，即具体产品子类 编写简单工厂类简单工厂类是一个具体的类，不是接口或抽象类。其中有一个 create() 方法，利用 if..else 或 switch 开关创建所需产品并返回。 使用简单工厂时，通常不用创建简单工厂类的实例，也没有必要，因此可以把简单工厂类实现成一个工具类，create() 作为静态方法就可以了。因此，简单工厂通常也叫静态工厂。如果不想让客户端创建简单工厂类，可以把简单工厂的构造方法私有化。来看一下示例代码：12345678910111213141516171819202122232425262728293031323334public interface Car &#123; // ...&#125;public class BigCar implements Car &#123; // ...&#125;public class MidCar implements Car &#123; // ...&#125;public class SmallCar implements Car &#123; // ...&#125;public class CarSimpleFactory &#123; public static final String BIGTYPE = "bigtype"; public static final String MIDTYPE = "midtype"; public static final String SmallType = "smalltype"; // 私有化构造方法 private CarSimpleFactory() &#123;&#125; public static Car create(String type) &#123; if (type.equals(BIGTYPE)) &#123; return new BigCar(); &#125; else if (type.equals(MIDTYPE)) &#123; return new MidCar(); &#125; else &#123; return new SmallCar(); &#125; &#125;&#125; 以上这段代码，其实存在一些问题。如果一个需求来了，需要增加一个 Car 类型，那么需要在简单工厂中再添加 switch / if 判断，这样会导致这个工厂类可能非常长，各种判断全都挤在一起，给扩展跟维护带来很多麻烦。也就是说，产品和工厂绑定在了一起，没有完全解耦。 有解决方案吗？当然有，继续往下读就知道了。 工厂方法工厂模式功能类的编写步骤如下： 编写抽象产品接口 编写接口实现类，即具体产品子类 编写抽象工厂类（或接口） 编写具体工厂子类 工厂模式把简单工厂中具体的工厂类划分成两层： 抽象工厂层 具体工厂子类层 工厂方法更易于软件的二次开发及维护。当需求发生变化时，只需要增加、删除相应的类，而不用修改已有的类。可以看下方示例代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546public interface Car &#123; // ...&#125;public class BigCar implements Car &#123; // ...&#125;public class MidCar implements Car &#123; // ...&#125;public class SmallCar implements Car &#123; // ...&#125;// 抽象工厂类public abstract class AbstractFactory &#123; public abstract Car create();&#125;public class BigCarFactory extends AbstractFactory &#123; public Car create() &#123; return new BigCar(); &#125;&#125;public class MidCarFactory extends AbstractFactory &#123; public Car create() &#123; return new MidCar(); &#125;&#125;public class SmallCarFactory extends AbstractFactory &#123; public Car create() &#123; return new SmallCar(); &#125;&#125;// 测试类 CarTest.javapublic class CarTest &#123; public static void main(String[] args) &#123; AbstractFactory factory = new BigCarFactory(); BigCar bigCar = factory.create(); &#125;&#125; 抽象工厂一般来说，简单工厂、工厂方法模式是单产品系的，而抽象方法是多产品系的。从本质上看，抽象工厂、工厂模式是统一的。 抽象工厂模式功能类的编写步骤如下： 编写抽象产品接口 编写具体产品子类 编写抽象工厂类（或接口），其中有两个 create() 方法，分别返回不同对象 编写具体工厂子类 看下方示例代码，应该就清楚了：123456789101112131415161718192021222324252627282930313233343536373839404142434445public interface Car &#123;&#125;public class BigCar implements Car &#123;&#125;public class MidCar implements Car &#123;&#125;public class SmallCar implements Car &#123;&#125;public interface Bus &#123;&#125;public class BigBus implements Bus &#123;&#125;public class MidBus implements Bus &#123;&#125;public class SmallBus implements Bus &#123;&#125;// 抽象工厂类，有 2 个 create() 方法public abstract class AbstractFactory &#123; public abstract Car createCar(); public abstract Bus createBus();&#125;public class BigFactory extends AbstractFactory &#123; public Car createCar() &#123; return new BigCar(); &#125; public Bus createBus() &#123; return new BigBus(); &#125;&#125;public class MidFactory extends AbstractFactory &#123; public Car createCar() &#123; return new MidCar(); &#125; public class createBus() &#123; return new MidBus(); &#125;&#125;public class SmallFactory extends AbstractFactory &#123; public Car createCar() &#123; return new SmallCar(); &#125; public Bus createBus() &#123; return new SmallBus(); &#125;&#125; 小结 简单工厂通过传入的标识来生产产品，不同产品都在同一个工厂中生产，扩展和维护较麻烦。 工厂模式无法解决多产品系的问题。 抽象工厂模式中，一个工厂生产多个产品，它们是一个产品系。 接口和抽象类都能用来表达抽象工厂或抽象产品，那么它们有何区别？👇抽象类偏向于属性的抽象，接口偏向于行为的规范与统一。使用接口有更好的扩展性和可维护性，更加灵活实现松散耦合。 参考资料👉 《Java 设计模式及应用案例分析》👉 《创建对象与使用对象——谈谈工厂的作用》👉 《面试被问设计模式？不要怕看这里：工厂模式》]]></content>
      <categories>
        <category>Design Pattern</category>
      </categories>
      <tags>
        <tag>factory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发系列——CAS 操作]]></title>
    <url>%2F2018%2F07%2F16%2Fcas%2F</url>
    <content type="text"><![CDATA[本文属译文，原文链接见文末。 CAS（Compare and Swap, 比较和替换）是设计并发算法经常会用到的技术。CAS 是将预期值与变量的具体值进行比较，如果相等，则将变量的值替换为新的值。比较和替换可能听起来有点复杂，但一旦理解它，其实相当简单😀，所以让我们再详细说明一下这个主题吧。 应用场景程序和并发算法中特别常见的模式是check and act模式。它先检查变量的值，然后根据该值进行操作。这儿有一个简单的例子：12345678910class MyLock &#123; private boolean locked = false; public boolean lock() &#123; if(!locked) &#123; locked = true; return true; &#125; return false; &#125;&#125; 如果在多线程应用程序中使用此代码会出现很多错误，但请暂时忽略它。 如你所见，lock() 方法首先检查(check) locked 成员变量是否为 false，若是，将 locked 值改(act)为 true。 如果多个线程可以访问同一个 MyLock 实例，则 lock() 方法无法保证上述功能正常工作。如果线程 A 检查 locked 并且看到值为 false，线程 B 也可以在完全相同的时间（或者在线程 A 将 locked 修改为 true 之前）检查该值。这样，线程 A、B都看到 locked 为 false，然后两者都将基于该信息起作用。 要在多线程应用程序中正常工作，check and act 操作必须是原子的。原子意味着check和act动作一起作为原子（不可分割）代码块执行，执行完成之前都不受其他线程的干扰。也就是说，没有其他线程可以同时执行原子代码块。 这是前面的代码示例，不过这里 lock() 方法使用 synchronized 关键字转换为原子代码块：12345678910class MyLock &#123; private boolean locked = false; public synchronized boolean lock() &#123; if(!locked) &#123; locked = true; return true; &#125; return false; &#125;&#125; 现在 lock() 方法是同步的，因此在同一个 MyLock 实例上一次只能有一个线程执行它 。该 lock() 方法实际上是原子的。 原子 lock() 方法实际上是 CAS 的一个例子。该 lock() 方法 将变量 locked 与预期值 false 进行比较，如果相等，则将变量的值替换为 true。 CAS 作为原子操作现代 CPU 内置了对 CAS 操作的支持。从 Java 5 开始，可以通过 java.util.concurrent.atomic 包中的一些新原子类来使用 CPU 的这些功能。 下面用一个示例来说明如何使用 AtomicBoolean 类实现 lock() 方法：123456public static class MyLock &#123; private AtomicBoolean locked = new AtomicBoolean(false); public boolean lock() &#123; return locked.compareAndSet(false, true); &#125;&#125; 注意 locked 变量不再是 boolean 类型 而是 AtomicBoolean 类型。此类有一个 compareAndSet() 函数，它将 AtomicBoolean 实例的值与期望值进行比较，如果相等，则将值与新值替换。上述示例代码中，它比较 locked 的值，如果是 false，则设置 AtomicBoolean 的新值为 true。 如果交换了值，则 compareAndSet() 返回true，否则返回 false。 使用 Java 5+ 附带的 CAS 功能而不是实现自己的功能的优点是，Java 5+ 中内置的 CAS 允许我们利用运行应用程序的 CPU 的基础 CAS 功能，这样代码运行效率更高。 原文链接👉 《Compare and Swap》]]></content>
      <categories>
        <category>Concurrence</category>
      </categories>
      <tags>
        <tag>cas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发系列——深入 synchronized 关键字]]></title>
    <url>%2F2018%2F07%2F15%2Fsynchronized%2F</url>
    <content type="text"><![CDATA[前言在 Java 并发编程中 synchronized 一直是👴元老级角色，很多人称呼它为重量级锁。但是，随着 JDK 1.6 对 synchronized 进行了各种优化后，有些情况下它并不那么笨重了。 实现原理synchronized 可以实现同步、内存可见性、原子性。 Java 中每个对象都可以作为锁🔒，这是 synchronized 实现同步的基础： 对于普通同步方法，锁是当前实例对象 对于静态同步方法，锁是当前类的 Class 对象 对于同步方法代码块，锁是 synchronized() 括号配置的对象 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须要释放锁。 从 JVM 规范中可以看到 synchronized 在 JVM 里的实现原理，JVM 基于进入和退出 Monitor 对象来实现方法同步和代码块同步，但两者的实现细节不同。 代码块同步使用 monitorenter 和 monitorexit 指令实现。 方法同步依靠方法修饰符上的 ACC_SYNCHRONIZED 实现。 来看一段简单代码：123456789public class SynchronizedTest &#123; // 普通同步方法 public synchronized void testSynchronizedMethod() &#123;&#125; // 同步方法代码块 public void testSynchronizedBlock() &#123; synchronized(SynchronizedTest.class) &#123;&#125; &#125;&#125; 在 cmd 使用 javap 命令 查看 .class 文件信息：1javap -v Synchronized.class 可以看到，对于同步代码块testSynchronizedBlock，monitorenter 指令插入到同步代码块的开始位置（见第 9 行），monitorexit 指令插入到同步代码块的结束位置（见第 11 行）。123456789101112131415161718public void testSynchronizedBlock(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: ldc #2 // class SynchronizedTest 2: dup 3: astore_1 4: monitorenter 5: aload_1 6: monitorexit 7: goto 15 10: astore_2 11: aload_1 12: monitorexit 13: aload_2 14: athrow 15: return 而同步方法testSynchronizedMethod则会被翻译成普通的方法和返回指令。在字节码层面并没有任何特别的指令来实现被 synchronized 修饰的方法，而在 .class 文件的方法表中将该方法的 flags 字段的 ACC_SYNCHRONIZED 标志位置 1（见第 3 行），表示该方法是同步方法并使用调用该方法的对象或该方法所属的 Class 对象表示 Klass 做为锁对象。12345678public synchronized void testSynchronizedMethod(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 5: 0 Java 对象头synchronized 用的锁存储在 Java 对象头里。如果对象是数组类型，则虚拟机用 3 个字宽存储对象头，如果对象是非数组类型，则用 2 字宽存储对象头。在 32 位虚拟机中，1 字宽等于 4 字节，即 32 bit。 Mark Word 用于存储对象自身的运行时数据，如哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID，偏向时间戳等。 在运行期间，Mark Word 里存储的数据会随着锁标志位的变化而变化。 Monitor对于 Monitor，我们可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。 每个 Java 对象都可以成为 Monitor，Monitor 是线程私有的，每一个线程都有一个可用 monitor record 列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个 Monitor 关联（对象头的 Mark Word 中的 LockWord 指向 Monitor 的起始地址），同时 Monitor 中有一个 Owner 字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 锁的升级与对比前面提到，JDK 1.6 对锁的实现进行了各种优化。为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在 JDK 1.6 中，锁一共有 4 种状态： 无锁状态 偏向锁状态 轻量级锁状态 重量级锁状态 这几个状态会随着竞争情况逐渐升级。锁可升级但不可降级，意味着偏向锁升级成轻量级锁后不能降级为偏向锁。这种策略，目的是为了提高获得锁和释放锁的效率。 参考资料👉 《Java 并发编程的艺术》👉 《死磕 Java 并发：深入分析 synchronized 的实现原理》]]></content>
      <categories>
        <category>Concurrence</category>
      </categories>
      <tags>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发系列——深入 volatile 关键字]]></title>
    <url>%2F2018%2F07%2F15%2Fvolatile%2F</url>
    <content type="text"><![CDATA[Java 内存模型在 Java 里，如果一个字段被声明成 volatile，Java 线程内存模型能确保所有线程看到的这个字段的值是一致的。 先来了解什么是 Java 内存模型。👇 Java 内存模型（简称 JMM）控制了线程之间的通信，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。 从抽象的层面来看，JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存存储着共享变量的副本。需要注意的是，本地内存只是 JMM 的一个抽象概念，不是真实存在。 若线程 A、B 之间要通信，必须经历以下两步： 线程 A 把本地内存 A 中更新的共享变量刷新到主内存中。 线程 B 到主内存中区读取线程 A 之间更新过的共享变量。 从整体上看，以上步骤实质是线程 A 向 B 发送消息，而且这个通信过程必须要经过主内存。JMM 通过控制主内存与每个线程的本地内存之间的交互，来保证内存可见性。 volatile 底层实现原理我们可以从汇编代码层面来看 volatile 变量。 对于一行 Java 代码：1instance = new Singleton(); //instance 是 volatile 变量 在 X86 处理器下，转换成汇编代码，会多出一行带有 Lock 前缀的指令：10x01a3de1d: movb $0×0,0×1104800(%esi);0x01a3de24: lock addl $0×0,(%esp); Lock 前缀的指令在多核处理器下会引发两个动作： 将当前处理器缓存行的数据写回到系统内存。 这个写回内存的操作会使其他 CPU 里缓存了该内存地址的数据无效。 为了提高处理速度，处理器不与内存直接通信，而是先将系统内存的数据读到本地缓存后再进行操作。如果对声明了 volatile 的变量进行✍写操作，JVM 会向处理器发送一条🔒 Lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。此时其他处理器缓存的值还是旧的，若再执行计算操作就会出现问题。 为了保证各个处理器的缓存是一致的，会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己当前缓存的值是否过期，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态🚩，当处理器对这个数据进行操作时，会重新从系统内存中把数据读到处理器缓存里。 volatile 特性 可见性：对于一个 volatile 变量的读，在任意线程总是能看到对这个 volatile 变量的最后写入。 原子性：对任意单个 volatile 变量的读/写具有原子性，但类型 volatile++ 这种复合操作不具有原子性。 参考资料👉 《Java 并发编程的艺术》]]></content>
      <categories>
        <category>Concurrence</category>
      </categories>
      <tags>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发系列——控制多线程的执行顺序]]></title>
    <url>%2F2018%2F07%2F13%2Fmulti-thread-execution-sequence%2F</url>
    <content type="text"><![CDATA[前言多线程在并发环境中的正常执行顺序是随机无序的，为什么呢？因为启动多个线程时，线程并不会立即执行，而是等待 CPU 的资源调度，CPU 调度到哪个线程，这个线程就开始执行，因此，多线程运行具有随机性。 想让多线程的执行顺序变得可控，常见的有以下两种方式。 join() 方法thread.join() 是把指定的线程加入到当前线程，它可以将两个交替执行的线程合并为顺序执行的线程。12345678910111213141516171819202122232425262728293031public class ThreadOrderTest &#123; static Thread t1 = new Thread(() -&gt; &#123; System.out.println("Thread1"); &#125;); static Thread t2 = new Thread(() -&gt; &#123; System.out.println("Thread2"); &#125;); static Thread t3 = new Thread(() -&gt; &#123; System.out.println("Thread3"); &#125;); public static void main(String[] args) throws InterruptedException &#123; t1.start(); t1.join(); t2.start(); t2.join(); t3.start(); t3.join(); /** * 程序打印结果： * Thread1 * Thread2 * Thread3 */ &#125;&#125; join() 方法底层其实是通过调用线程的 wait() 方法来达到同步的目的。见下方源码： 例如，主线程中调用了 t1 线程的 join() 方法，则相当于主线程调用了 t1 线程的 wait() 方法，在调用了 t1 线程的 wait() 方法后，主线程就会进入阻塞状态。当 t1 线程执行完（或者到达等待时间），t1 线程会自动调用自身的 notifyAll() 方法唤醒主线程，从而达到同步的目的。123456789101112131415161718192021222324public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125; &#125; Executors.newSingleThreadExecutor()利用并发包里 Executors 的 newSingleThreadExecutor() 产生一个单线程的线程池，而这个线程池的底层原理就是一个先进先出（FIFO）的队列。代码中 service.submit()依次添加了 3 个线程，按照 FIFO 的特性，执行顺序也就是 Thread1.2.3 的执行结果。 1234567891011121314151617181920import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class ThreadOrderTest &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newSingleThreadExecutor(); service.submit(() -&gt; &#123; System.out.println("Thread1"); &#125;); service.submit(() -&gt; &#123; System.out.println("Thread2"); &#125;); service.submit(() -&gt; &#123; System.out.println("Thread3"); &#125;); service.shutdown(); &#125;&#125;]]></content>
      <categories>
        <category>Concurrence</category>
      </categories>
      <tags>
        <tag>multi-thread, sequence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[忙碌的一周]]></title>
    <url>%2F2018%2F07%2F12%2Fbusy-week%2F</url>
    <content type="text"><![CDATA[这周一到周四，每天都约了一个面试，都约在下午。每天早上泡在图书馆吹着冷气看书学习，下午顶着大热天到外面赴面试。 挺充实的一周，我珍惜每一次面试的机会，每一次都能发现自身的不足。 以前的自己有点害怕面试，自身不是很健谈，见人容易害羞，自我介绍有时都支支吾吾的；而且也对自己没有信心，总觉得有好多东西还没准备好，自己是不是应该准备充分之后再投简历面试。这一次算是鼓起了勇气迈开了这一步，也收到了实习 Offer，对自己更有信心了😄。 明天没有面试，是该好好总结一下了。 晚上到学校健身房锻炼了两个小时，特别累。前段时间一直没有锻炼，体能有所下降，接下来要多加运动了。 好像有点语无伦次……就这样吧，刚从健身房回来，码点字，歇一会儿后洗个澡缓解一下运动疲劳~]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解 HashMap 底层实现原理]]></title>
    <url>%2F2018%2F07%2F11%2Flearn-hashmap%2F</url>
    <content type="text"><![CDATA[前言面试中经常会遇到 HashMap 相关的问题，以前没有做深入的研究，导致在面试过程中没能把原理跟面试官讲清楚😭。这一次必须彻底弄懂才行✊。 什么是哈希表哈希表也叫散列表，它的主干其实是数组。我们知道，在数组中查找某一个元素，只需要根据下标就能一次定位到，而哈希表正是利用了这一特性。 举个栗子🌰，我们要新增或查找某个元素，只要把当前元素的关键字通过某个函数映射到数组中的某个位置，通过数组下标的一次定位就能完成操作。即：位置 = f(关键字)。f 函数其实就是哈希函数，这个函数设计的好坏会直接影响到哈希表的性能。 哈希冲突如果两个不同的元素，通过哈希函数计算出的实际存储地址相同，那该怎么办？也就是说，当我们对某个元素进行哈希运算而得到一个存储地址，然后要进行插入，发现此时该位置已经被其他元素“霸占”了，这其实就是所谓的“哈希冲突”，也叫“哈希碰撞”👊。 前面已经提到，哈希函数设计至关重要，一个好的哈希函数会尽可能保证计算简单和散列地址分布均匀，也就是说，对任意 key，f(key) 对应不同地址的概率相等。但是数组是一块连续固定长度的内存空间，再好的哈希也无法保证得到的存储地址绝对不会冲突。那么当发生哈希冲突，该如何处理呢？ 常见的有以下几种处理方式： 开放定址法（再散列法）当 key 对应的哈希地址 p=f(key) 出现冲突时，以 p 为基础，产生另一个哈希地址，若依然冲突，继续以 p 为基础，产生另一个哈希地址 p2……直到找到一个不冲突的哈希地址 pi，将元素存入其中。这种方式有一个通用的再散列函数形式，其中 f(key) 为哈希函数，m 为表长，di 为增量序列。增量序列的取值方式不同，相应的再散列方式也不同：pi = (f(key) + di) % m，(i = 1, 2, ..., n) 再哈希法这种方式是同时构造多个不同的哈希函数，当哈希地址 f1(key) 发生冲突时，再计算 f2(key)……直到不再发生冲突。这种方式不易产生聚集现象，但增加了计算的时间。 pi = f1(key)，(i = 1, 2, ..., k) 链地址法这种方式是将所有哈希地址为 i 的元素构成一个单链表，并将单链表中的头指针存在哈希表的第 i 个单元中，因此查找、插入和删除主要是在链表中进行。链地址法适用于经常进行插入和删除的情况。HashMap 就是采用这种方式😮，数组 + 链表。 HashMap 原理分析HashMap 的主干是一个 Entry 数组。Entry 是 HashMap 的基本组成单元，每一个 Entry 包含一个 key-value 键值对。 简单来说，HashMap 由“数组 + 链表”组成的，数组是 HashMap 的主体，链表主要为了解决哈希冲突，如果定位到的数组位置不含链表（即当前 entry 的 next 指向 null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度为 O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，同样需要遍历链表，然后通过 key 对象的 equals 方法逐一比对查找。所以，性能考虑，HashMap 中的链表出现越少，性能才会越好。 HashMap 的初始化在 HashMap 实例化时需要了解两个概念：初始容量和加载因子。HashMap 基于哈希表的 Map 接口实现，初始容量是哈希表在创建时的容量。加载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度。当哈希表中的条目数超过了加载因子与当前容量的乘积时，则要对该哈希表进行 rehash 操作（即重建内部数据结构），从而哈希表将具有大约两倍于当前容量的新的容量。12345678910111213141516171819202122232425//默认初始容量 16static final int DEFAULT_INITIAL_CAPACITY = 16;//定义最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认负载因子 0.75static final float DEFAULT_LOAD_FACTOR = 0.75f;transient Entry[] table;//临界值，值为容量与加载因子的乘积int threshold; //加载因子final float loadFactor; public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; threshold = (int)(DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR); table = new Entry[DEFAULT_INITIAL_CAPACITY]; init();&#125;void init() &#123;&#125; 以上构造方法定义了一个空的 HashMap，其默认初始容量为 16，默认初始加载因子为 0.75，同时声明了一个 Entry 类型的数组，数组初始长度为 16。 HshMap 的底层数据结构]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列——单例模式]]></title>
    <url>%2F2018%2F07%2F10%2Fsingleton-pattern%2F</url>
    <content type="text"><![CDATA[单例模式保证一个类仅有一个实例，并提供一个访问它的全局访问点。当系统需要某个类只能有一个实例时，就可以采用单例模式。 保证单例模式仅有一个实例的核心思想是构造方法私有化，即不允许外部调用该类的构造方法。基于此思想，主要有以下两种实现方式： 直接实例化直接实例化这种方式也称作“饿汉式”，它直接定义了静态成员变量 s，并通过 new Singleton() 完成了初始化，之后不再变化，是线程安全的。这种方式也存在一定的资源浪费，当没有使用 Singleton 对象时，程序依然会创建 Singleton 对象。1234567public class Singleton &#123; private Singleton() &#123;&#125; private static final Singleton s = new Singleton(); public static Singleton getInstance() &#123; return s; &#125;&#125; 延迟实例化既然直接实例化浪费资源，那么我们是否可以考虑，在程序需要该对象的时候才创建它呢？当然可以！与直接实例化稍不同，单例成员变量 s 初始为 null，它在方法 getInstance() 内部完成延迟实例化，并返回单例对象。12345678910public class Singleton &#123; private Singleton() &#123;&#125; private static Singleton s = null; public static Singleton getInstance() &#123; if (s == null) &#123; s = new Singleton(); &#125; return s; &#125;&#125; 这种方式存在线程安全问题。例如，假设两个线程调用 getInstance() 方法，线程 1 执行完 if(s == null)，条件成立，在执行实例化语句 s = new Singleton() 之前，线程 2 来了，此时线程 2 执行 if(s == null)，依然成立，进入 if 语句体。这种情况带来的后果是：程序两次创建了对象，这并不符合我们对单例模式的定义。 针对这种情况，可以有以下四种解决方法： 完全同步完全同步方法，是在方法上加上 synchronized 同步。当多线程同时访问 getInstance() 方法时，多线程是“串行”的。12345678910public class Singleton &#123; private Singleton() &#123;&#125; private static Singleton s = null; public static synchronized Singleton getInstance() &#123; if (s == null) &#123; s = new Singleton(); &#125; return s; &#125;&#125; 这种方法，多线程每次访问 getInstance() 都必须“串行”运行，效率比较低。 部分同步部分同步方法通过双重锁部分同步机制获得单例对象。因为代码中有两行相同的语句 if(s == null)，故而叫做双重锁。第一个 if 语句可并行，当多线程均满足该条件， synchronized 修饰的代码必须串行运行。这样的话，其实只需要在第一次创建对象（通过了第一个 if 判断）的时候进行同步，效率较高。1234567891011121314public class Singleton &#123; private Singleton() &#123;&#125; private volatile static Singleton s = null; public static Singleton getInstance() &#123; if (s == null) &#123; synchronized(Singleton.class) &#123; if (s == null) &#123; s = new Singleton(); &#125; &#125; &#125; return s; &#125;&#125; 注意，volatile关键字是确保当 s 被初始化成 Singleton 实例时，多个线程可以正确处理 s，即内存可见性。 静态内部类通过静态内部类 Inner 来实现单例对象。虚拟机加载应用程序字节码时，单例对象并不会立即创建，当第一次运行 Inner.s 时，单例对象才动态生成。这种实现方式无 synchronized 关键字，提高了效率。123456789public class Singleton &#123; private Singleton() &#123;&#125; private static class Inner &#123; private static final Singleton s = new Singleton(); &#125; public static Singleton getInstance() &#123; return Inner.s; &#125;&#125; 枚举这是单例模式的最佳实践，它实现简单，并且在面对复杂的序列化或者反射攻击的时候，能够防止实例化多次。调用的时候只需要 Singleton.INSTANCE 即可。1234567891011public enum Singleton &#123; INSTANCE; // var here public int var; // methods here public void otherMethods() &#123; System.out.println("write other methods here..."); &#125;&#125; enum 实现 Singleton 的三个特性：自由序列化、线程安全、保证单例。 首先， enum 是由 class 实现的，它可以有 member 和 member function。另外，由于 enum 是通过继承 Enum 类实现的，enum 结构不能作为子类继承其他类，但可以用来实现接口。此外 enum 类不能被继承，在反编译中，可以发现该类由 final 修饰。 其次，enum 有且仅有 private 的构造器，防止外部的额外构造，这恰好与单例模式吻合。 而对于序列化和反序列化，因为每一个枚举类型和枚举变量在 JVM 中都是唯一的，即 Java在序列化和反序列化枚举时做了特殊的规定，枚举的 writeObject、readObject、readObjectNoData、writeReplace 和 readResolve 等方法是被编译器禁用的，因此也不存在实现序列化接口后调用readObject 会破坏单例的问题。 （完） 参考资料👉 《Head First 设计模式》👉 《Java 设计模式及应用案例分析》👉 《Java 枚举 enum 以及应用：枚举实现单例模式》]]></content>
      <categories>
        <category>Design Pattern</category>
      </categories>
      <tags>
        <tag>singleton</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一学期又结束了]]></title>
    <url>%2F2018%2F07%2F07%2Ffinish-final-exam%2F</url>
    <content type="text"><![CDATA[昨天下午考完了最后一科《编程语言》，我的大学课程算是完全修完了（应该不至于挂科）… 从 2016 年开始，因为修读了软件工程第二学位，我比身边不少小伙伴少了很多空闲时间，平时忙于做实验写报告，跟他们一起出去玩耍的机会也少了。 我不后悔修读软件工程双学位。我已经决定毕业之后从事Programming的职业，既是兴趣爱好，也是性格所向。我个人比较内敛😳，不是很擅长与别人打交道，相信跟我相处过的人都知道，但我会与别人相处得很好，不会闹什么小矛盾。前段时间有朋友来找我说要不要一起租房，他毕业了，想找一个比较靠谱的朋友一起合租，我听了是很感动(ಥ _ ಥ)的，但因为双学位的原因，我还有一年时间才毕业，所以暂时没机会一起租房了。另外，我喜欢编程，相比于各种杂七杂八的活动、四处跑业务，我更喜欢安安静静坐在电脑💻前Coding，虽然有时因为调bug而四处碰壁，但在fixed bugs后，我会开心得像个小屁孩😀活蹦乱跳~ 在去年 7 月份我决定做Java开发，但那时，我对 Java 是一无所知，我至今不知道自己当时哪来的冲动突然选了 Java 方向。一直坚持到今天，自学了一年 Java 的我，觉得自己在 Java 方面进步还是挺大的~ 接下来还有很多事情要做，实习、秋招、两份毕业设计，💪加油干吧~]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>talk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统知识总结3]]></title>
    <url>%2F2018%2F07%2F04%2Fall-os3%2F</url>
    <content type="text"><![CDATA[存储器管理存储器的层次结构 CPU 寄存器 Cache 高速缓存 主存储器（内存/主存） 磁盘缓存 固定磁盘 可移动存储介质 在存储层次中，层次越高（越靠近 CPU），存储介质的访问速度越快，价格也就越高，相应所配置的存储容量也越小。高速缓存、主存储器和磁盘缓存均属于操作系统存储管理的管辖范畴，掉电后存储的信息就不存在了。而低层的固定磁盘和可移动存储介质则属于设备管理的管辖范畴，它们存储的信息将被长期保存。 存储器的管理目标 为用户使用存储器提供方便，用户只需要在自己的逻辑内存空间编程，不需要考虑真实内存的物理位置。 为用户提供充分大的存储空间。 提高内存的利用率，将尽量多的用户调入内存运行。 程序的装入和链接程序进入内存的流程步骤： 编译：源代码 -&gt; 目标模块 链接：目标模块 + 库函数 -&gt; 装入模块 装入：装入内存 连续分配方式为了能将用户程序装入内存，必须为它分配一定大小的内存空间。连续分配方式是最早出现的一种存储器分配方式，该方式是为一个用户程序分配一个连续的内存空间。有以下几种分配方式： 单一连续分配在单道程序环境下，内存分为系统区和用户区两部分。整个内存的用户空间由该程序独占。 固定分区连续分配（容易造成浪费）将内存划分为多个区域，每个区域大小固定且只能装入一个程序。分区大小相等的划分一般用于多个相同任务；分区大小不等的划分一般根据实际任务大小分配。 动态分区分配无固定分区，在整块内存空间中动态分割；根据程序大小，动态分配连续的内存空间，分配的内存大小等于程序大小。 基于顺序搜索的动态分区分配算法为了实现动态分区分配，通常是将系统中的空闲分区链接成一个链。顺序搜索，是指依次搜索空闲分区链上的空闲分区，去寻找一个其大小能满足要求的分区。有以下几种算法： 首次适应算法首次适应（First Fit, FF）算法是按顺序选择第一个满足要求的内存区域。优点：保留了高地址的大部分空间，为以后到达的大作业分配大的内存空间创造了条件。缺点：低址部分不断被划分，会留下许多难以利用的、很小的空间（碎片）。 循环首次适应算法循环首次适应（Next Fit, NF）算法是在上一次找到空闲分区的下一个分区开始寻找，找到第一个满足要求的内存区。优点：空闲分区在内存中分配均匀，查找时间短。缺点：缺乏大的内存空间。 最佳适应算法最佳适应（Best Fit, BF）算法是指每次为作业分配内存时，总是把能满足要求、又是最小的空闲分区分配给作业，避免“大材小用”。优点：提高内存利用率，保留大空闲区。缺点：仍然存在小片无法利用的空闲分区（碎片）。 动态可重定位分区分配对内存中正在使用的分区进行搬迁，使多个小的空闲分区（碎片）合并为一个大的空闲分区。 基本分页存储管理方式 页面：逻辑上的划分，进程空间管理上的划分，简称页。页是操作系统分配内存的最小单位。 物理块：物理上的划分。 页与物理块的关系： 页的大小与物理块大小完全相等。 进程任何一个页都可以装入内存的任何一个物理块。 进程除了最后一个页可能会产生碎片，其他页都是刚好装入各个物理块中。 各个页离散地分布在不同物理块中。 页的编号在逻辑地址上是连续的，在物理块分布上是离散的。 页表记录了进程每一页在内存存放的块号。页内地址直接对应块内地址。 地址转换机构：地址转换是将用户空间中的逻辑地址转换为内存空间中的物理地址。而页内地址与物理地址一一对应，因此地址变换机构的任务的任务实际上只是将逻辑地址中的页号转换为内存中的物理块号。 基本分段存储管理方式分段是指将一个进程划分为多个具有逻辑意义而且相对独立的部分。例如主程序段、数据段、堆栈段、子程序段等……每个段都有独立的名称，为了管理方便，用段号表示。在逻辑地址意义上，每个段包含两部分：段号、段内地址。作业空间与内存空间的映射，借助于段表：😀分页与分段的区别： 页是信息的物理单位，满足系统空间管理需要，分页实现离散分配方式，以消减内存的外零头， 提高内存的利用率；段是信息的逻辑单位，每个段含有一组意义完全的信息，分段是为了满足程序员在编写代码时的一些逻辑需求，比如数据共享、数据保护。 页的大小固定，由系统决定；段的长度不固定， 由用户决定。 段页式管理方式段面向用户程序需要，段长度不固定；段需要连续分配空间，存在连续分配的缺点，例如易产生碎片；结合段式和页式两者管理优点，既能节省内存空间，提高内存分配效率；又能兼顾用户程序需要。 段页式管理机制： 分段与分页机制的结合； 先将用户程序划分为多个有逻辑意义的段，再将段划分为多个页； 段页式管理需要设置段表和页表； 每个段都对应一张页表，因此段表存放了每张页表的开始地址和页表长度。 页面置换算法在程序运行过程中，如果要访问的页面不在内存中，就会发生缺页中断，从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区，从而腾出空间给要访问的页面。 页面置换算法是为了找出以后不再访问的页面或者较长时间不再使用的页面，达到具有较低的页面更换频率（低缺页率）的目标。 最佳置换算法该算法所选择的换出页在未来最长一段时间内不再被访问，通常可以保证获得最低的缺页率。但这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 先进先出页面置换算法该算法淘汰最先进入内存的页面，即选择内存驻留时间最长的，只看“进入顺序”。该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。 最近最久未使用置换算法虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 算法选择最近最久未使用的页面，增加访问字段(t)记录各个页面未被访问的周期数。LRU 置换算法需要硬件支持，硬件（移位寄存器/栈）需要解决以下两个问题： 进程各个页面有多久未被访问； 如何快速找到最近最久未使用的页面。 😀移位寄存器： 每个寄存器记录进程在内存中每页的使用情况； 数据格式：R=Rn-1Rn-2Rn-3….R2R1R0； 页面被访问一次，最高位Rn-1置 1，每隔一定时间，寄存器右移一位； R值最小的页面是被置换页。 😀堆栈： 采用特殊的栈来保存当前使用的各个页面号； 栈顶保留的是最新被访问的页； 栈底保留的是最久未被访问的页，即置换目标。 简单 Clock 置换算法该算法是 LRU 算法的近似算法，也称为最近未用算法。它为每一页设置一访问位，实际编程中用整型数组来表示当前业内是否被访问，1 代表被访问过，0 代表未访问过。每次置换，指针循环遍历，找出第一个访问位为 0 的那个内存页面。若该页面访问位为 1，则将访问位置 0，指针继续移动。 改进型 Clock 置换算法每个页面设置有访问位 A 和修改位 M，两个位组合成四种类型的页面（见下方表格）执行过程： 从当前指针位置开始扫描循环队列，寻找第 1 类页面，不改变访问位 A，将遇到的第一个这类页面作为淘汰页； 第一步查找失败，寻找第 2 类页面，将遇到的第一个这类页面作为淘汰页。在扫描期间，所有扫描过的页面的访问位 A 都置 0； 所有 3 类页面变成 1 类页面，4 类页面变成 2 类页面； 第二步失败，重复第一步； 如果仍失败，再重复第二步，此时就一定能找到被淘汰的页。 页面类别 访问位 A 访问位 M 描述 1 0 0 最近未被访问，又未被修改，最佳淘汰页。 2 0 1 最近未被访问，但已被修改页。 3 1 0 最近已被访问， 但未被修改。 4 1 1 最近已被访问且被修改，最不应淘汰页。 最少使用算法最少使用（Least Frequently Used, LFU）置换算法对每个页面设置一个字段（移位寄存器），用来记录页面被访问的频率。 磁盘管理磁盘的结构磁盘由多个盘片组成，每个盘片分为两个盘面，每个盘面分若干个磁道（同心圆），每个磁道分若干个扇区。 磁盘调度算法 先来先服务每个请求按照时间顺序来处理。缺点是平均寻道距离较大。 最短寻道时间优先平均寻道时间较短。缺点是：“饥饿”现象，即某些进程长期得不到访问；“磁臂粘着”现象，即磁头可能长期停留在同一磁道。 扫描SCAN，又称为电梯调度算法，针对最短寻道优先的“饥饿”现象进行改进，依据磁头移动方向访问当前磁道最近的目标磁道。 循环扫描CSCAN，到达最外磁道后，返回最内磁道开始扫描。磁头移动方向固定不变，不会中途折返。优点是不会出现“饥饿”现象，平均寻道时间较短，最长等待时间比扫描算法少一半。缺点是“磁臂粘着现象仍未解决。 N-Step-SCAN 算法为了解决“磁臂粘着”现象，将请求序列划分为多个子序列，新请求只能进入后面的子序列，不能进入当前子序列，避免粘着现象。 FSCAN 算法N-Step-SCAN 算法的简化版，只划分两个子序列，一个当前序列，一个后备序列。 🤭 操作系统知识总结系列完~👉 Previous.]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统知识总结2]]></title>
    <url>%2F2018%2F07%2F04%2Fall-os2%2F</url>
    <content type="text"><![CDATA[处理机调度处理机调度的层次 高级调度（作业调度）根据调度算法和计算机状态，从外存选择一个或多个作业调入内存。 创建进程 分配内存等资源 将进程放入就绪队列等待 CPU 调度。 低级调度（进程调度）它决定哪个进程获得 CPU。 保存现场 调度新进程 新进程获得 CPU 控制权 中级调度（内存调度）中级调度是为了提高内存利用率和系统吞吐量。为此，把那些暂时不能运行的进程调至外存等待，此时进程的状态为挂起状态。当它们具备运行条件且内存又稍有空闲时，再重新调入内存，并修改器状态为就绪状态。 三级调度队列模型 处理机调度常见名词 到达时间：进入系统的时间 开始时间：首次使用 CPU 的时间 服务时间：需要使用 CPU 的时间，也叫“运行时间” 完成时间：退出系统的时间 周转时间：完成时间 - 到达时间 带权周转时间：周转时间 / 服务时间 平均周转时间：周转时间的平均值 平均带权周转时间：带权周转时间的平均值 调度算法 先来先服务调度算法先来先服务（First-Come First-Served, FCFS）调度算法按照作业到达的先后次序进行调度，它优先考虑在系统中等待时间最长的作业。（不利于短作业）FCFS 算法在单处理机系统中已很少作为主调度算法，但经常把它与其它调度算法相结合使用，形成更有效的调度算法。例如可以在系统中按进程的优先级设置多个队列，每个优先级一个队列，其中每一个队列的调度算法都基于 FCFS 算法。 短作业优先调度算法短作业优先（Short Job First, SJF）调度算法以作业的长短来计算优先级，它从外存的后备队列中选择若干个估计运行时间最短的作业，优先将它们调入内存运行。（不利于长作业，未考虑作业的紧迫程度） 优先级调度算法前面两种算法不能反映作业的紧迫程度，在优先级调度算法（Priority-Scheduling Algorithm, PSA）中，则是基于作业的紧迫程度，由外部赋予作业相应的优先级，调度算法是根据该作业的优先级进行调度的。 高响应比优先调度算法高响应比优先调度算法（Highest Response Ratio Next, HRRN）既考虑了作业的等待时间，又考虑了额作业的运行时间。优先权 = (等待时间 + 服务时间) / 服务时间等待时间相同，服务时间越短优先权越高；服务时间相同，等待时间越长优先权越高。（每次调度前都要计算优先权，增加系统开销） 基于时间片的轮转调度算法 将所有就绪进程按先来先服务排成队列 把 CPU 分配给队首进程，进程只执行一个时间片 时间片用完，OS 通过计时器发出时钟中断，停止进程 将已使用时间片的进程送至就绪队列末尾 分配 CPU 给就绪队列的下一个进程 多级反馈队列调度算法设置多个就绪队列，各个队列优先级逐个降低，时间片长度成倍增加。即，优先级越高的队列执行时间片就越短。多级反馈队列调度算法的调度规则： 每个新进程首先进入第一个队列，遵循 FCFS。 在当前队列的时间片内，进程若能完成，退出。 进程若未完成，降到第二个队列，同样遵循 FCFS。 依此类推…… 低级队列只有等高级队列变空才能执行。 当高级队列有新进程进入，而当前正在运行低级队列的进程，将立即发生抢占，被抢占进程放回低级队列的末尾，记录进程剩余运行时间和在当前队列的剩余使用时间。 实时调度在实时系统中，可能存在着一些实时任务，它们都联系着一个截止时间。为保证系统能正常工作，实时调度必须能满足实时任务对截止时间的要求。 最早截止时间优先算法最早截止时间优先（Earliest Deadline First, EDF）算法是根据任务的截止时间确定任务的优先级，任务的截止时间越早，其优先级越高，具有最早截止时间的任务排在队列的队首。 最低松弛度优先算法最低松弛度优先（Least Laxity First, LLF）算法是根据任务紧急程度确定任务的优先级，任务的紧急程度越高，优先级就越高。松弛度 = 完成截止时间- 运行时间(服务时间) - 当前时间例如，任务 A 的完成截止时间是第 400s，运行时间为 100s，当前时间是第 150s，则 A 的松弛度 = 400-100-150 = 150s 在松弛度为 0 的时刻设置“地雷”，松弛度为 0 发生抢占。 死锁产生死锁的必要条件 互斥进程对所分配的资源进行排它性使用，即在一段时间内，某资源只能被一个进程占用。如果此时还有其它进程请求该资源，则请求进程只能等待，直到占有该资源的进程释放。 请求与保持进程已经持有了至少一个资源，但又提出新的资源请求。 不可剥夺已获得的资源在使用完之前，不能被抢占，只能在进程使用完自己释放。 环路等待存在一个“进程——资源”循环链，进程间互相等待资源。 处理死锁的方法 预防死锁设置限制条件，破坏产生死锁的一个或多个必要条件。比如，强制回收资源、资源一次性分配…… 避免死锁在资源动态分配过程中，加入检查，防止系统进入不安全状态。 检测死锁建立检测机构检测死锁的发生和原因，确定相关的进程和资源。 解除死锁剥夺资源或撤销进程，从而解除死锁。 避免死锁的方法在死锁避免方法中，把系统的状态分为安全状态和不安全状态。当系统处于安全状态时，可避免发生死锁。反之，当系统处于不安全状态时，则可能进入到死锁状态。所谓安全状态，是指系统能按某种进程顺序 &lt;P1, P2, …，Pn&gt; 来为每个进程Pi分配其所需资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利地完成，称 &lt;P1, P2, …, Pn&gt; 序列为安全序列。如果系统无法找到这样一个安全序列，则称系统处于不安全状态。 数据结构的定义： 定义 描述 Max 进程对各种资源的最大需求 Allocation 进程已占用（分配）的各种资源的数量 Need 进程对各种资源的剩余需求量 Available 系统当前可用资源数量 Work 每个进程完成后系统可用资源数量（初始值为 Available） Finish 每个进程能否完成 银行家算法银行家算法原本是为银行系统设计的，以确保银行在发放现金贷款时，不会发生不能满足所有客户需要的情况。当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给该进程。若有，再进一步计算在将这些资源分配给进程后，是否会使系统处于不安全的状态。如果不会，才将资源分配给它。判断方法： 虚拟执行这个分配请求，使得当前状态进入下一个状态； 在下一个状态中寻找安全序列； 若找到，说明状态安全，可以执行分配请求；否则拒绝分配请求。 算法缺点： 很少进程能够在运行前就知道它所需资源的最大值。 系统内的进程数是不固定的，往往在不断变化，有新的进入，有完成的退出。 😄 To be continued.👉 Next.👉 Previous.]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统知识总结]]></title>
    <url>%2F2018%2F07%2F01%2Fall-os%2F</url>
    <content type="text"><![CDATA[操作系统概论操作系统的作用 作为用户与计算机硬件系统之间的接口。 作为计算机系统资源的管理者。 实现对计算机资源的抽象。 操作系统的四个基本特性 并发在一段时间内多个程序并发执行。 共享系统中的资源可以被内存中多个并发执行的进线程共同使用。 虚拟通过分时系统以及虚拟内存技术实现把一个物理实体虚拟为若干个逻辑上的对应物。 异步系统中的进程以不可预知的速度向前推进，但只要运行环境相同，多次运行都会获得完全相同的结果。 操作系统的主要功能 处理机管理：进程控制、进程同步、进程通信、CPU 调度 存储器管理：内存分配、地址映射 设备管理：缓冲管理、设备分配、设备处理、虚拟设备 文件管理：存储空间管理、目录管理 用户接口：图形接口、命令接口 进程基本概念程序顺序执行的特征 顺序性：下一操作要等待前一操作执行结束。 封闭性：执行独占资源，不受外界影响。 可再现性：重复执行得到相同结果。 程序并发执行的特征 间断性 失去封闭性 不可再现性：重复执行可引发多种结果。 程序并发的三个特征使得程序不能并发地正确执行，为了保证程序并发执行，引入进程。 进程的结构进程由程序、数据、进程控制块(PCB)三部分组成。 程序：代码段，描述进程要完成的功能。 数据：数据段，进程执行时所需要的数据区。 进程控制块：一种数据结构，用于标识进程的存在，记录进程执行过程中各个时刻的状态特征。 进程的四个特性 动态：进程具有生命周期，从创建，执行，到消亡。 并发：多个进程共存于内存中，并发执行。 独立：进程间资源独立，互不干扰。进程是系统进行资源分配和调度的一个独立单位。 异步：每个进程都以其相对独立，不可预知的速度前进。 进程与程序的区别 进程是动态的执行实体，程序是静态的数据与指令的集合。 一个程序可以包含多个进程。 进程用于并发执行与接受调度，程序用于存储数据和接受系统启动。 进程执行需要 CPU，程序存储需要存储器。 进程具有生命周期，程序是永存的。 进程的三种基本状态 就绪状态：已获得除 CPU 以外的其他所有资源，处于就绪队列，等待 CPU 调度。 执行状态：获得 CPU，处于执行过程。 阻塞状态：某个事件暂时无法进行，主动放弃 CPU。 PCB 的作用PCB 中包含进程标识符、处理机状态、进程调度信息、进程控制信息。所以 PCB 具有以下作用： 进程存在的唯一标识 记录进程的外部特征 描述进程变化的过程 记录进程和其他进程的联系 PCB 的组织方式 链接方式：把具有相同状态的进程的 PCB 分别通过 PCB 中的链接字段链接成一个队列。优先级高的进程 PCB 排在队列前面。 索引方式：根据进程状态的不同建立索引。 原语操作原语由若干指令组成，是用于完成一定功能的一个过程。原语操作是一种原子操作；原语中的操作要么全做，要么全不做。 进程控制进程创建 申请空白 PCB； 为新进程分配资源； 初始化 PCB； 如果进程就绪队列能够接纳新进程，就将新进程插入就绪队列。 进程终止 根据标识符从 PCB 集合中检索出 PCB，读取进程状态； 若正处于执行状态，立即终止该进程的执行，并置调度标志位真，在进程被终止后重新调度； 终止该进程的子孙进程，以防止成为不可控的进程； 回收资源，归还给父进程/系统； PCB 移出所在队列或链表。 进程阻塞（对应唤醒）执行过程中，当发现引发阻塞的事件而无法继续执行时，进程调用阻塞原语block把自己阻塞。 停止当前执行； 修改状态，由执行改为阻塞； 将 PCB 插入阻塞队列，若有因不同事件而划分的多个阻塞队列，阻塞进程插入相应队列； 重新调度，将处理机分配给另一就绪进程； CPU 环境切换，保存被阻塞进程的 CPU 状态到 PCB 中，按新进程 PCB 的 CPU 状态设置 CPU 新环境。 进程唤醒被阻塞的事件已满足，如 I/O 完成或所需数据已到达，则由有关进程调用唤醒原语wakeup，将阻塞的进程唤醒： 先把被阻塞的进程从等待该事件的阻塞队列中移出； 将其 PCB 状态由阻塞改为就绪； 再将该 PCB 插入到就绪队列中。 进程挂起（对应激活）挂起是将活动状态改为静止状态的过程。 挂起一般有以下几个原因： 终端用户的请求：当终端用户发现自己程序运行期间有可疑进程时，需要挂起检查。 父进程的请求：有时父进程希望挂起自己的某个子进程，以便考察和修改子进程，或者协调各子进程间的活动。 负载调节的需要：保证系统正常运行。 操作系统的需要：操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况。 挂起原语的执行过程如下： 检查被挂起进程的状态，活动就绪改为静止就绪；活动阻塞改为静止阻塞； 将 PCB 复制到指定的内存区域； 数据复制到外存，释放内存； 若被挂起的进程正在执行，则重新调度。 进程激活当发生激活进程的事件，如父进程或用户进程请求激活，或当前内存有足够的空间，系统利用激活原语active将进程激活。 激活原语的执行过程如下： 先将进程从外存调入内存； 检查该进程的现行状态，静止就绪改为活动就绪；静止阻塞改为活动阻塞； 若是进入就绪队列，则重新调度，抢占式和非抢占式调度。 进程同步进程同步的任务是使并发执行的诸进程之间能有效地共享资源和相互合作，从而使进程的执行具有可再见性。同步机制应遵循的规则： 空闲让进 忙则等待 有限等待 让权等待 信号量机制 整型信号量使用一个代表资源数目的整型变量。未遵循“让权等待”规则。 记录型信号量增加一个进程链表 L，用于链接所有等待进程。初始值为 1，表示只允许一个进程访问临界资源，此时的信号量转换为互斥信号量。 AND 型信号量将进程在整个运行过程中需要的所有资源，一次分配给进程，待进程使用完后再一起释放。即：要么全部分配到进程，要么一个也不分配。 管程管程是一种共享数据结构，对该共享数据结构实施的特定操作定义为一组过程。进程对共享资源的申请、释放和其他操作必须通过这组过程。 局部数据变量只能被管程的过程访问，任何外部过程都不能访问。 一个进程通过调用管程的一个过程进入管程。 在任何时候，只能有一个进程在管程中执行，调用管程的任何其它进程都被阻塞。 生产者——消费者问题可以利用“记录型信号量、AND 型信号量、管程”来解决生产者——消费者问题，这里演记录型信号量的使用。假设有n个缓冲区。 变量 功能/描述 mutex 实现诸进程对缓冲区的互斥访问（公有） empty 缓冲池中空缓冲区的数量（私有） full 缓冲池中满缓冲区的数量（私有） 1234567891011// 生产者producer:begin repeat produce an item nextp; wait(empty); // 先私 wait(mutex); // 后公 buffer(in) ∶= nextp; in ∶= (in + 1) mod n; signal(mutex); signal(full); until false; 12345678910// 消费者consumer:begin repeat wait(full); // 先私 wait(mutex); // 后公 nextc ∶= buffer(out); out ∶= (out + 1) mod n; signal(mutex); signal(empty); consume the item in nextc; 哲学家进餐问题五个哲学家进餐，如何避免死锁？ 至多只允许有四位哲学家同时去拿左边的筷子 当哲学家的左、右两只筷子均可用时，才允许他拿起筷子进餐。 规定奇数号哲学家先拿他左边的筷子，然后再去拿右边的筷子；而偶数号哲学家则相反。 读者——写者问题 一个数据文件可被多个进程共享 允许多个进程同时读，禁止多个进程同时写 当一个进程写的时候，其他所有读进程都要停止 当进程读的时候，不允许写进程的发生。 读写是互斥的。 12345678910111213141516171819202122232425var rmutex, wmutex:semaphore = 1, 1; readcount:integer = 0; begin parbegin reader:begin repeat wait(rmutex); if readcount = 0 then wait(wmutex); readcount ∶= readcount + 1; signal(rmutex); perform read operation; wait(rmutex); readcount = readcount - 1; if readcount = 0 then signal(wmutex); signal(rmutex); until false; end writer:begin repeat wait(wmutex); perform write operation; signal(wmutex); until false; 进程通信进程间通信（IPC, InterProcess Communication）是指在不同进程之间传播或交换信息。 进程通信方式 共享内存（最快）同一块物理内存被映射到进程 A、进程 B 各自的进程空间。进程 A 可以即时看到进程 B 对共享内存中数据的更新，反之亦然。由于多个进程共享同一块内存区域，必然需要使用同步机制，互斥锁和信号量都可以。 管道管道是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又叫pipe文件。写进程：以字符流形式将大量的数据送入共享文件，即送入管道。读进程：从管道中接收数据，即从共享文件中读数据。管道只支持半双工通信（单向传输）；只能在父子进程中使用；管道实质是采用文件的读写操作，支持大数据量的传输。 命名管道即 FIFO 文件，通过命名管道可以实现在不相关的进程之间交换数据。 消息队列消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。每个数据块都被认为含有一个类型，接收进程可以独立地接收含有不同类型的数据结构。相比于 FIFO，消息队列具有以下优点： 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 套接字与其它通信机制不同的是，它可用于不同机器间的进程通信。 进程与线程的区别 地址空间进程之间是独立的地址空间，而同一进程的线程则共享本进程的地址空间。 资源拥有进程之间的资源是独立的，而同一进程内的线程共享本进程的资源，如内存、I/O、CPU 等。一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃后整个进程都死掉。所以多进程要比多线程健壮。 执行过程每个独立的进程有一个程序运行的入口、顺序执行序列和程序入口，而线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 线程是处理机调度的基本单位，但是进程不是。 因此，对资源的管理和保护要求高、不限制开销和效率时，使用多进程。要求效率高、频繁切换、资源的保护管理要求不是很高时，使用多线程。 😄 To be continued.👉 Next.]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络——应用层]]></title>
    <url>%2F2018%2F06%2F30%2Fapplication-layer%2F</url>
    <content type="text"><![CDATA[HTTP 协议HTTP 协议（HyperText Transfer Protocal, 超文本传输协议）是用于从 WWW 服务器传输超文本到本地浏览器的传送协议。它基于 TCP 协议之上，属于应用层协议。 HTTP 请求响应模型HTTP 是一个无状态的协议。无状态是指客户端和服务器之间不需要建立持久的连接，这意味着当一个客户端向服务器发送请求，服务器返回响应之后，连接即关闭了，在服务端不保留连接的有关信息。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络——传输层]]></title>
    <url>%2F2018%2F06%2F29%2Ftransport-layer%2F</url>
    <content type="text"><![CDATA[传输层概述在 OSI（Open System Interconnection, 开发系统互联）七层模型中，传输层是面向通信的最高层，也是面向用户功能的最底层。 传输层有两大功能： 复用：在发送端，多个应用进程共有一个传输层。 分用：在接收端，传输层根据端口号将数据分派给不同的应用进程。 传输层和网络层的区别： 网络层是为不同主机提供通信服务，而传输层是为不同主机的不同应用程序提供通信服务。 网络层只对报文头部进行差错检测，而传输层对整个报文进行差错检测。 UDP 协议UDP 的特点UDP（User Datagram Protocol, 用户数据报协议）有以下特点： 无连接通信前不需要建立连接，通信结束也无须释放连接。 不可靠UDP 是尽力而为交付，不能确保每个数据报都送达。 面向报文UDP 数据传输的基本单位是报文，它不会对数据做任何拆分或拼接操作。在发送端，应用程序给传输层的 UDP 什么数据，UDP 不会对数据进行拆分，只增加一个 UDP 头后就交给网络层；在接收端，UDP 收到网络层的数据报后，不会作任何拼接操作，去掉数据报头后便交给应用层。 没有拥塞控制UDP 始终以恒定的速率发送数据，它不会根据网络拥塞情况对发送速率作出调整。这种方式可能导致数据丢失，但可以应用在“直播、语音通话”这种允许数据丢失、但对实时性要求较高的场景。 支持一对一、一对多、多对一、多对多通信 首部开销小，只有 8 字节 UDP 头部UDP 头部只有 8 字节，包括： 16 位源端口 16 位目的端口 16 位 UDP 长度 16 位 UDP 检验和 TCP 协议TCP 的特点TCP（Transmission Control Protocol, 传输控制协议）有以下特点： 面向连接通信前需要建立连接，通信结束后需要释放连接。 可靠TCP 发送的数据无重复、无丢失、与发送端顺序一致。 面向字节流TCP 以字节位单位，传输的过程中数据被划分成一个个数据报。 全双工通信TCP 的两端既可以作为发送端，也可以作为接收端。 一条 TCP 连接的两端只能有两个端点TCP 只能提供点到点的通信，而 UDP 可以任意方式的通信。一条 TCP 连接的两端就是两个套接字，套接字 = IP: 端口号。 TCP 头部TCP 头部通常有 20 字节，有选项时更长，但总共不超过 60 字节。包括： 源端口、目的端口（共 4 字节）传输层和网络层的一大重要区别就是：传输层指定了数据报发往的应用进程，因此需要端口号标识。 序号（4 字节）当前 TCP 数据报数据部分的第一个字节的序号。TCP 是面向字节流的，它会对发送的每一个字节进行编号，而且不同数据报之间是连续编号的。 确认号（4 字节）表示当前主机作为接收端，期望接收的下一个字节的编号。 数据偏移（4 字节）数据部分距离报文段起始部分的偏移，其实就是头部的长度。 保留字段 标识符 URG：该字段被置 1 时，表示当前数据报的数据部分包含紧急信息，紧急数据一定是在数据部分的最前面，紧急指针标明了紧急数据的尾部。 ACK：该字段被置 1 时，确认号字段才有效。在连接建立后传送的所有报文短都必须把 ACK 置 1。 PSH：当接收方收到 PSH=1 的报文后，会立即将数据交给应用程序，而不是等到缓冲区满了后才提交。 RST：该值为 1 时，表示当前 TCP 连接出现严重问题，需要释放重连。 SYN：SYN 在建立连接的时候使用。（SYN=1, ACK=0）表示当前报文段是一个连接请求报文；（SYN=1, ACK=1）表示当前报文是一个同意建立连接的应答报文。 FIN：FIN=1 表示此报文段是一个释放连接的请求报文。 接收窗口大小表示当前接收窗口的剩余容量大小，用于实现 TCP 的流量控制。发送方收到该值后会将发送窗口调整为该值的大小。发送窗口的大小又影响了发送速率，所以接收方通过设置该值控制发送方的发送速率。 检验和用于接收端检验整个数据报在传输过程中是否出错。 紧急指针用于标识紧急数据的尾部。 选项字段长度可选。 TCP 三次握手假设 A 为客户端，B 为服务端。 首先 B 处于LISTEN状态，等待 A 的连接请求。 A 向 B 发送请求报文， （SYN=1, ACK=0），发送后 A 进入SYN-SENT状态。 B 收到 A 的请求报文，如果同意建立连接，则向 A 发送连接确认报文段，（SYN=1, ACK=1），发送后 B 进入SYN-RCVD状态。 A 收到 B 的连接确认报文段，还要向 B 发送一个确认报文段，发送后 A 进入ESTABLISHED状态，B 收到后也进入ESTABLISHED状态，从而连接建立。 为什么是三次握手？而不是两次？其实是防止失效的连接被服务端接收，导致服务端错误打开连接而浪费资源。如果建立连接只需要两次握手，客户端没有太大变化，它在获得服务端的应答后进入ESTABLISHED状态，而服务端会在收到连接请求后就进入ESTABLISHED状态。此时如果网络拥塞，客户端发送的请求迟迟到不了服务端，客户端会超时重发，如果服务端正确接收并确认应答，双方开始通信，通信接收后释放连接。此时如果那个失效的连接请求抵达服务端，由于只有两次握手，服务端会进入ESTABLISHED状态，而此时客户端早已进入CLOSED状态，服务端会一直等待下去，从而浪费服务端连接资源。 TCP 四次挥手TCP 连接的释放一共需要四步，称为“四次挥手”。前两次挥手用于断开一个方向的连接，后两次挥手用于断开另一个方向的连接。 A 发送连接释放报文段， FIN=1，之后进入FIN-WAIT-1状态。 B 收到后，向 A 发送连接应答，进入CLOSE-WAIT状态。 A 收到该应答，进入FIN-WAIT-2状态，等待 B 发送连接释放的请求。 当 B 不再需要连接时，向 A 发送连接释放的请求报文， FIN=1，之后 B 进入LAST-ACK状态。 A 收到释放请求后，向 B 发送应答，进入TIME-WAIT状态，等待 2MSL 后进入CLOSED状态，B 收到应答后，也进入CLOSED状态。 为什么 A 要先进入TIME-WAIT状态，等待 2MSL 时间后再进入CLOSED状态？其实是为了保证 B 能收到 A 的确认应答。若 A 发完确认应答后直接CLOSED，如果该应答丢失，B 等待超时，会重新发送释放连接的请求，此时 A 已经关闭了，不会作出任何响应，B 永远无法正常关闭。 TCP 可靠传输的表现TCP 的可靠性在于，它向应用层提供的数据是无差错、有序、无丢失的。TCP 采用流量控制、拥塞控制、连续 ARQ 等技术保证它的可靠性。 停止等待协议（ARQ 协议）TCP 保证其可靠性采用的是更为复杂的滑动窗口协议，但停止等待协议是它的简化版，因此这里先介绍停止等待协议。ARQ（Automatic Repeat reQuest, 自动重传请求），就是当请求失败时它会自动重传，直到请求被正确接收为止。 无差错的情况A 向 B 每发送一个分组，都要停止发送，收到 B 的确认应答后才发送下一个分组。 分组丢失、出现差错的情况分组丢失：分组在途中丢失，B 收不到，因此不会有响应，A 超时后会重传。出现差错：B 收到分组，但检查到分组有差错，会直接丢弃，不会有响应，A 同样超时重传。 应答丢失、应答迟到的情况应答丢失：B 收到分组，返回应答，但应答在途中丢失了，A 超时重传，紧接着 B 又收到该分组，判断该是否已接收，若已接收则直接丢弃，并补上一个应答。应答迟到：B 收到分组，返回应答，但由于网路拥塞，A 没有及时收到分组，导致超时重传，之后前面的应答抵达 A，A 判断是否已接收，若是则直接丢弃即可。 滑动窗口协议（连续 ARQ 协议）在 ARQ 协议中，发送者每次只能发送一个分组，在应答到来前必须等待，而连续 ARQ 协议的发送者拥有一个发送窗口，发送者可以在没有得到应答的情况下连续发送窗口中的分组。这样减少了等待时间，提高了传输的效率。 窗口是缓存的一部分，用来暂时存放字节流。发送者和接收者各有一个窗口，接收者通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送者根据这个值和其它信息设置自己的窗口大小。 如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 如果某些字节并未按序收到，接收者只会确认最后一个有序的字节，从而乱序的字节就会被重新发送。 TCP 协议的两端分别为发送者 A 和接收者 B，由于是全双工通信，因此 A 和 B 应该分别维护着一个独立的发送缓冲区和接收缓冲区。 TCP 流量控制流量控制是为了避免分组丢失，通过控制发送方发送速率，保证接收方来得及接收。它通过滑动窗口协议实现。 流量控制可能引发死锁。当发送者收到一个窗口为 0 的应答时，进入等待状态，等待接收者的下一个应答。如果下一个窗口不为 0 的应答在途中丢失，会导致发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待下去，从而产生死锁。为了避免死锁，TCP 使用了持续计时器，每当发送者收到一个 0 窗口的应答后就启动计数器，时间一到会询问接收者窗口的大小。若依然为 0，则重新启动计时器，如此下去…… TCP 拥塞控制如果网络出现拥塞，分组将会丢失，此时发送者会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送者的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收者能来得及接受，而拥塞控制是为了降低整个网络的拥塞程度。 TCP 主要通过四种算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。 发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 慢开始与拥塞避免发送的最初执行慢开始，令 cwnd=1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 …注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。如果出现了超时，则令 ssthresh = cwnd/2，然后重新执行慢开始。 快重传与快恢复对于接收者，要求每次接收到报文段都应该发送对已收到有序报文段的确认，例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。而对于发送方，如果收到三个重复确认，那么可以确定下一个报文段丢失，例如收到三个 M2 ，则 M3 丢失。此时执行快重传，立即重传下一个报文段。在这种情况下，只是丢失个别报文段，而不是网络拥塞，因此执行快恢复，令 ssthresh = cwnd/2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>UDP</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[免费搭建属于自己的博客]]></title>
    <url>%2F2018%2F06%2F29%2Fbuild-your-own-blog%2F</url>
    <content type="text"><![CDATA[对于一个没有一点编程基础的同学来说，搭建这样的一个博客，难吗？ 不难，说真的。但不是说很简单，它需要你去了解一些小知识点，比如 Git 命令行的使用、GitHub 仓库的创建、代码的远程部署等等……它不像我们安装某些软件一样，只要把安装包下载下来，运行安装程序，一路 next 到最后完成即可。 这篇文章里，我会大致说一下搭建的流程以及用到的每个工具的作用，但不会详细讲一步步具体该怎么操作，因为网上有太多详细的教程了，只要你会用搜索引擎。 安装 GitGit 是一个版本控制软件，或者说是一个管理代码的工具，特别适合用于团队的协作开发中。在公司，一般是团队协作完成软件/系统的开发，同事把代码提交到远程仓库，你可以在自己电脑上通过 Git 命令将代码克隆下来，创建分支，加进去你的代码，提交的时候可以 merge 合并分支，协作完成开发工作。 我们搭建自己的博客，需要将代码部署到 GitHub 上，用的就是 Git 的一些基本命令，比如 commit、push… 安装 Node.js我的这个博客用的是 Hexo 框架，它基于 Node.js 开发，因此，在安装 Hexo 之前，首先需要安装 Node.js。而 npm 是 Node.js 的一个包管理工具，安装完 Node.js 之后，就有了 npm。通过 npm 我们可以把搭建博客需要的一些代码包（如 Hexo）下载下来并完成安装。 安装 Hexo通过执行 npm 命令安装即可。 初始化博客安装完 Hexo，在自己喜欢的文件夹下初始化 Hexo 博客，并配置一些相关信息，比如博客网站的标题、语言(zh-Hans)等等。 安装主题这一步可以不做，你完全可以用 Hexo 的默认主题，只是我嫌弃它默认的主题样式不好看，因此安装了 nexT 主题样式，看起来舒服多了，这个过程可以做一些个性化配置，比如文章的展示方式……只要在主题文件夹下修改 _config.yml 文件的配置信息即可。 在 GitHub 上创建仓库以上我们是在自己电脑上操作的，外部无法访问到我们的博客，因此，可以将页面代码部署到 GitHub 仓库上，由 GitHub 帮我们解析页面供外部访问。部署的时候，需要有密钥，一般是用 SSH，保证只有自己能上传代码到自己的仓库上。部署完成之后，基本上就搞定了。 添加 GitmentGitment 是一款基于 GitHub Issues 的评论系统，可以为我们的博客添加评论功能，完全不需要后台服务器，用户的每一条评论会存储到 GitHub 的 Issues 上，你可以像我一样，将评论添加在自己的博客仓库中，也可以新创建一个仓库专门用于存储评论。 评论时需要用户登录 GitHub 账号，没有 GitHub 账号的用户是评论不了的，这与 Gitment 基于 GitHub Issues 有关。 似乎就这么多了，详细的搭建过程以及如何开始文章的创作，查看网上教程就好了，我就不把链接贴出来了~]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再见，德国]]></title>
    <url>%2F2018%2F06%2F28%2FGoodbye-Germany%2F</url>
    <content type="text"><![CDATA[生活无比残酷，幸运女神不会永远眷顾着你，还是要坚强面对生活。 再见，日耳曼战车。]]></content>
      <categories>
        <category>Life</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Just Do IT]]></title>
    <url>%2F2018%2F06%2F27%2FJust-Do-IT%2F</url>
    <content type="text"><![CDATA[复习计划 JVM Java Web Spring MyBatis 设计模式 操作系统 数据库 计算机网络 数据结构与算法 Java 基础 Java 并发 Java 容器 Java IO 查漏补缺数据库索引、优化、引擎HashMap 底层源码网络协议（TCP为什么 3 次握手; HTTP）设计模式（23种！都要过关，待总结）]]></content>
      <categories>
        <category>Dev</category>
      </categories>
      <tags>
        <tag>plan</tag>
      </tags>
  </entry>
</search>
